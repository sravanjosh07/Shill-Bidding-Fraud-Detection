{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "db02c9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "import warnings\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder,label_binarize, MinMaxScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from hpelm import ELM\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, auc, accuracy_score\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b009ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bidder_ID</th>\n",
       "      <th>Bidder_Tendency</th>\n",
       "      <th>Bidding_Ratio</th>\n",
       "      <th>Successive_Outbidding</th>\n",
       "      <th>Last_Bidding</th>\n",
       "      <th>Auction_Bids</th>\n",
       "      <th>Starting_Price_Average</th>\n",
       "      <th>Early_Bidding</th>\n",
       "      <th>Winning_Ratio</th>\n",
       "      <th>Auction_Duration</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Auction_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>_***i</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>g***r</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>t***p</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>7***n</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.097477</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>z***z</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Bidder_ID  Bidder_Tendency  Bidding_Ratio  Successive_Outbidding  \\\n",
       "Auction_ID                                                                    \n",
       "732            _***i         0.200000       0.400000                    0.0   \n",
       "732            g***r         0.024390       0.200000                    0.0   \n",
       "732            t***p         0.142857       0.200000                    0.0   \n",
       "732            7***n         0.100000       0.200000                    0.0   \n",
       "900            z***z         0.051282       0.222222                    0.0   \n",
       "\n",
       "            Last_Bidding  Auction_Bids  Starting_Price_Average  Early_Bidding  \\\n",
       "Auction_ID                                                                      \n",
       "732             0.000028           0.0                0.993593       0.000028   \n",
       "732             0.013123           0.0                0.993593       0.013123   \n",
       "732             0.003042           0.0                0.993593       0.003042   \n",
       "732             0.097477           0.0                0.993593       0.097477   \n",
       "900             0.001318           0.0                0.000000       0.001242   \n",
       "\n",
       "            Winning_Ratio  Auction_Duration  Class  \n",
       "Auction_ID                                          \n",
       "732              0.666667          0.444444      0  \n",
       "732              0.944444          0.444444      0  \n",
       "732              1.000000          0.444444      0  \n",
       "732              1.000000          0.444444      0  \n",
       "900              0.500000          0.666667      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Group_14_data_cleaned.csv\", index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffe035a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5646\n",
       "1     675\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fbdf4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = data.drop(['Class', 'Bidder_ID'], axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92058d4",
   "metadata": {},
   "source": [
    "# ELM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "efbb9cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELMClassifier:\n",
    "    def __init__(self, n_hidden=512, activation=\"tanh\", n_classes=2):\n",
    "        self.n_hidden = n_hidden\n",
    "        self.activation = activation\n",
    "        self.n_classes = n_classes\n",
    "        self.elm = ELM(inputs=X_train.shape[1], outputs=2, classification=\"c\")\n",
    "        self.elm.add_neurons(n_hidden, activation)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y_bin = label_binarize(y, classes=range(self.n_classes))\n",
    "        self.elm.train(X, y_bin)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = self.elm.predict(X)\n",
    "        return np.argmax(y_pred, axis=1)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        y_pred = self.elm.predict(X)\n",
    "        return y_pred\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y, y_pred)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {'n_hidden': self.n_hidden, 'activation': self.activation, 'batch': self.batch, 'n_classes': self.n_classes}\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for param, value in params.items():\n",
    "            setattr(self, param, value)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b64f1db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9873517786561264\n",
      "[[1122   11]\n",
      " [   5  127]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      1133\n",
      "           1       0.92      0.96      0.94       132\n",
      "\n",
      "    accuracy                           0.99      1265\n",
      "   macro avg       0.96      0.98      0.97      1265\n",
      "weighted avg       0.99      0.99      0.99      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Scale the training and testing data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "# One-hot encode the target variable\n",
    "encoder = OneHotEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train.reshape(-1, 1)).toarray()\n",
    "y_test_encoded = encoder.transform(y_test.reshape(-1, 1)).toarray()\n",
    "\n",
    "# Train and evaluate the ELM model on the scaled data\n",
    "elm_classifier = ELMClassifier()\n",
    "elm_classifier.fit(X_train_scaled, y_train_encoded)\n",
    "score = elm_classifier.score(X_test_scaled, y_test)\n",
    "print(\"Accuracy:\", score)\n",
    "\n",
    "\n",
    "# Get the predicted labels and convert them back from one-hot encoding\n",
    "y_pred_encoded = elm_classifier.predict_proba(X_test_scaled)\n",
    "y_pred = np.argmax(y_pred_encoded, axis=1)\n",
    "\n",
    "# Get the true labels and convert them back from one-hot encoding\n",
    "y_true = np.argmax(y_test_encoded, axis=1)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(conf_matrix)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e486e9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neurons: 16 Accuracy: 0.9557312252964427\n",
      "Neurons: 32 Accuracy: 0.9675889328063241\n",
      "Neurons: 64 Accuracy: 0.9731225296442688\n",
      "Neurons: 128 Accuracy: 0.9778656126482214\n",
      "Neurons: 256 Accuracy: 0.9818181818181818\n",
      "Neurons: 512 Accuracy: 0.9873517786561264\n",
      "Neurons: 1024 Accuracy: 0.9857707509881423\n",
      "{'best_score': 0.9873517786561264, 'best_neurons': 512}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Scale the training and testing data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "\n",
    "# One-hot encode the target variable\n",
    "encoder = OneHotEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train.reshape(-1, 1)).toarray()\n",
    "y_test_encoded = encoder.transform(y_test.reshape(-1, 1)).toarray()\n",
    "\n",
    "\n",
    "n_neurons = [16, 32, 64, 128, 256, 512, 1024]\n",
    "scores = []\n",
    "\n",
    "for neurons in n_neurons:\n",
    "    # Train and evaluate the ELM model on the scaled data\n",
    "    elm_classifier = ELMClassifier(n_hidden=neurons)\n",
    "    elm_classifier.fit(X_train_scaled, y_train_encoded)\n",
    "    score = elm_classifier.score(X_test_scaled, y_test)\n",
    "    print(\"Neurons:\", neurons, \"Accuracy:\", score)\n",
    "    scores.append(score)\n",
    "\n",
    "best_score = max(scores)\n",
    "best_neurons = n_neurons[scores.index(best_score)]\n",
    "result = {'best_score': best_score, 'best_neurons': best_neurons}\n",
    "print(result)\n",
    "\n",
    "# Plot the scores with the number of neurons\n",
    "plt.plot(n_neurons, scores)\n",
    "plt.xlabel('Number of neurons')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('ELM accuracy vs. number of neurons')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e80f1c",
   "metadata": {},
   "source": [
    "We can see that ELM performs the best for number of neurons: 512 and the score reduces by increasing the number of neurons further. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9ae720",
   "metadata": {},
   "source": [
    "# Training with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2beafeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9865612648221344\n",
      "[[1120   13]\n",
      " [   4  128]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      1133\n",
      "           1       0.91      0.97      0.94       132\n",
      "\n",
      "    accuracy                           0.99      1265\n",
      "   macro avg       0.95      0.98      0.97      1265\n",
      "weighted avg       0.99      0.99      0.99      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the ELM model on the scaled data\n",
    "elm_classifier = ELMClassifier(n_hidden=512)\n",
    "elm_classifier.fit(X_train_scaled, y_train_encoded)\n",
    "score = elm_classifier.score(X_test_scaled, y_test)\n",
    "print(\"Accuracy:\", score)\n",
    "\n",
    "\n",
    "# Get the predicted labels and convert them back from one-hot encoding\n",
    "y_pred_encoded = elm_classifier.predict_proba(X_test_scaled)\n",
    "y_pred = np.argmax(y_pred_encoded, axis=1)\n",
    "\n",
    "# Get the true labels and convert them back from one-hot encoding\n",
    "y_true = np.argmax(y_test_encoded, axis=1)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(conf_matrix)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72a015d",
   "metadata": {},
   "source": [
    "## SVM with Linear Kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f86b9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'C': 2.209602254061174, 'gamma': 3.935350823412439, 'kernel': 'linear'}\n",
      "AUC score:  0.9849473524897286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "\n",
    "# Define AUC as a scoring metric\n",
    "auc_scorer = make_scorer(roc_auc_score)\n",
    "\n",
    "# RANDOM SEARCH FOR 20 COMBINATIONS OF PARAMETERS\n",
    "rand_list = {\"C\": stats.uniform(2, 10),\n",
    "             \"gamma\": stats.uniform(0.1, 5),\n",
    "             'kernel': ['linear']}\n",
    "\n",
    "rand_search = RandomizedSearchCV(SVC(), \n",
    "                                 param_distributions=rand_list, \n",
    "                                 n_iter=50, \n",
    "                                 n_jobs=4, \n",
    "                                 cv=3, \n",
    "                                 random_state=2017, \n",
    "                                 scoring=auc_scorer) \n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding accuracy score\n",
    "print(\"Best hyperparameters: \", rand_search.best_params_)\n",
    "print(\"AUC score: \", rand_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab9be25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1103   30]\n",
      " [   2  130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99      1133\n",
      "           1       0.81      0.98      0.89       132\n",
      "\n",
      "    accuracy                           0.97      1265\n",
      "   macro avg       0.91      0.98      0.94      1265\n",
      "weighted avg       0.98      0.97      0.98      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the best hyperparameters to create a new SVM model\n",
    "best_svm_model = SVC(C=rand_search.best_params_['C'], kernel=rand_search.best_params_['kernel'], gamma=rand_search.best_params_['gamma'])\n",
    "\n",
    "# Train the new SVM model using the training data\n",
    "best_svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained classifier to predict the class labels for the test data\n",
    "y_pred = best_svm_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluate the classifier's performance on the test data\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045f168e",
   "metadata": {},
   "source": [
    "## SVM with non linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b958a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'C': 18.52669390630025, 'gamma': 0.2563640674119393, 'kernel': 'rbf'}\n",
      "Accuracy score:  0.9932756288184654\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the model\n",
    "svm_model = SVC()\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "rand_list = {\"C\": stats.uniform(2, 100),\n",
    "             \"gamma\": stats.uniform(0.1, 10),\n",
    "             'kernel': ['rbf', 'poly']}\n",
    "\n",
    "# Perform the randomized search\n",
    "rand_search = RandomizedSearchCV(svm_model, param_distributions=rand_list, n_iter=50, n_jobs=-1, cv=3, random_state=42, scoring='accuracy')\n",
    "rand_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding accuracy score\n",
    "print(\"Best hyperparameters: \", rand_search.best_params_)\n",
    "print(\"Accuracy score: \", rand_search.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "36eff0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1115   18]\n",
      " [   7  125]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1133\n",
      "           1       0.87      0.95      0.91       132\n",
      "\n",
      "    accuracy                           0.98      1265\n",
      "   macro avg       0.93      0.97      0.95      1265\n",
      "weighted avg       0.98      0.98      0.98      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the best hyperparameters to create a new SVM model\n",
    "best_svm_model = SVC(C=rand_search.best_params_['C'], kernel=rand_search.best_params_['kernel'], gamma=rand_search.best_params_['gamma'])\n",
    "\n",
    "# Train the new SVM model using the training data\n",
    "best_svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained classifier to predict the class labels for the test data\n",
    "y_pred = best_svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier's performance on the test data\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccbd283",
   "metadata": {},
   "source": [
    "## Training a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "237bf94a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.4619 - accuracy: 0.8935 - 703ms/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.3196 - accuracy: 0.8935 - 139ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.2562 - accuracy: 0.8935 - 139ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.2094 - accuracy: 0.8935 - 135ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.1744 - accuracy: 0.8935 - 152ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.1423 - accuracy: 0.8967 - 140ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.1106 - accuracy: 0.9593 - 136ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0810 - accuracy: 0.9739 - 139ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0622 - accuracy: 0.9789 - 150ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0534 - accuracy: 0.9801 - 173ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0560 - accuracy: 0.9769 - 275ms/epoch - 5ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.5474 - accuracy: 0.8600 - 839ms/epoch - 8ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.3189 - accuracy: 0.8956 - 196ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.2100 - accuracy: 0.8956 - 183ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.1518 - accuracy: 0.9386 - 178ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.1067 - accuracy: 0.9644 - 202ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0809 - accuracy: 0.9644 - 150ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0674 - accuracy: 0.9671 - 128ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0606 - accuracy: 0.9712 - 157ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0563 - accuracy: 0.9697 - 190ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0540 - accuracy: 0.9778 - 184ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0559 - accuracy: 0.9674 - 193ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.5200 - accuracy: 0.8609 - 606ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.3656 - accuracy: 0.8888 - 128ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.2947 - accuracy: 0.8888 - 130ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.2381 - accuracy: 0.8888 - 129ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.1941 - accuracy: 0.8888 - 128ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.1576 - accuracy: 0.8911 - 156ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.1254 - accuracy: 0.9522 - 159ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0996 - accuracy: 0.9656 - 187ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0802 - accuracy: 0.9727 - 196ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0682 - accuracy: 0.9736 - 203ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0630 - accuracy: 0.9703 - 253ms/epoch - 5ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.5058 - accuracy: 0.8407 - 711ms/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.2264 - accuracy: 0.9273 - 172ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0914 - accuracy: 0.9682 - 176ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0614 - accuracy: 0.9727 - 151ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0540 - accuracy: 0.9736 - 134ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0494 - accuracy: 0.9777 - 157ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0459 - accuracy: 0.9780 - 176ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0449 - accuracy: 0.9804 - 200ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0432 - accuracy: 0.9813 - 167ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0428 - accuracy: 0.9810 - 134ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0518 - accuracy: 0.9769 - 189ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.4845 - accuracy: 0.8816 - 698ms/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.2429 - accuracy: 0.9077 - 143ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.1012 - accuracy: 0.9656 - 134ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0617 - accuracy: 0.9733 - 135ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0544 - accuracy: 0.9748 - 138ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0494 - accuracy: 0.9783 - 129ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0478 - accuracy: 0.9766 - 132ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0475 - accuracy: 0.9775 - 135ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0456 - accuracy: 0.9786 - 161ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0450 - accuracy: 0.9789 - 152ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0462 - accuracy: 0.9822 - 218ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.4914 - accuracy: 0.8677 - 597ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.3083 - accuracy: 0.9042 - 160ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.1292 - accuracy: 0.9600 - 163ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0678 - accuracy: 0.9721 - 164ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0538 - accuracy: 0.9760 - 186ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0479 - accuracy: 0.9789 - 180ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0461 - accuracy: 0.9789 - 139ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0442 - accuracy: 0.9789 - 156ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0427 - accuracy: 0.9792 - 136ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0419 - accuracy: 0.9789 - 132ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0413 - accuracy: 0.9840 - 227ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.4692 - accuracy: 0.8680 - 731ms/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.1857 - accuracy: 0.9270 - 173ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0651 - accuracy: 0.9718 - 193ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0486 - accuracy: 0.9766 - 185ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0444 - accuracy: 0.9819 - 173ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0415 - accuracy: 0.9828 - 160ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0398 - accuracy: 0.9831 - 151ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0384 - accuracy: 0.9840 - 182ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0369 - accuracy: 0.9843 - 195ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0374 - accuracy: 0.9855 - 209ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0475 - accuracy: 0.9769 - 196ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.3977 - accuracy: 0.8864 - 707ms/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0956 - accuracy: 0.9641 - 143ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0564 - accuracy: 0.9727 - 144ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0499 - accuracy: 0.9772 - 141ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0465 - accuracy: 0.9780 - 150ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0449 - accuracy: 0.9783 - 185ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0449 - accuracy: 0.9795 - 195ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0433 - accuracy: 0.9789 - 220ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0420 - accuracy: 0.9786 - 163ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0413 - accuracy: 0.9792 - 154ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0365 - accuracy: 0.9840 - 225ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.4339 - accuracy: 0.8365 - 723ms/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.1463 - accuracy: 0.9427 - 139ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0604 - accuracy: 0.9736 - 140ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0482 - accuracy: 0.9798 - 142ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0444 - accuracy: 0.9801 - 140ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0424 - accuracy: 0.9801 - 140ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0416 - accuracy: 0.9810 - 141ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0401 - accuracy: 0.9819 - 141ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0399 - accuracy: 0.9840 - 141ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0396 - accuracy: 0.9831 - 137ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0391 - accuracy: 0.9852 - 186ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.3336 - accuracy: 0.8985 - 612ms/epoch - 6ms/step\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 - 0s - loss: 0.0632 - accuracy: 0.9754 - 141ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0465 - accuracy: 0.9804 - 141ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0429 - accuracy: 0.9819 - 143ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0407 - accuracy: 0.9813 - 142ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0395 - accuracy: 0.9819 - 142ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0372 - accuracy: 0.9840 - 142ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0377 - accuracy: 0.9849 - 142ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0368 - accuracy: 0.9849 - 143ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0399 - accuracy: 0.9825 - 142ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0500 - accuracy: 0.9751 - 185ms/epoch - 3ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.3243 - accuracy: 0.8822 - 609ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0714 - accuracy: 0.9683 - 144ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0494 - accuracy: 0.9766 - 140ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0497 - accuracy: 0.9763 - 139ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0436 - accuracy: 0.9804 - 141ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0431 - accuracy: 0.9789 - 141ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0422 - accuracy: 0.9804 - 147ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0405 - accuracy: 0.9798 - 140ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0401 - accuracy: 0.9822 - 144ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0397 - accuracy: 0.9822 - 140ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0357 - accuracy: 0.9852 - 181ms/epoch - 3ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.3325 - accuracy: 0.8837 - 580ms/epoch - 5ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0643 - accuracy: 0.9700 - 142ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0493 - accuracy: 0.9786 - 140ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0451 - accuracy: 0.9780 - 142ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0438 - accuracy: 0.9786 - 141ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0426 - accuracy: 0.9798 - 141ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0407 - accuracy: 0.9819 - 147ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0388 - accuracy: 0.9843 - 141ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0385 - accuracy: 0.9855 - 147ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0383 - accuracy: 0.9834 - 162ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0372 - accuracy: 0.9834 - 197ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.2136 - accuracy: 0.9344 - 682ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0466 - accuracy: 0.9801 - 177ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0421 - accuracy: 0.9813 - 176ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0408 - accuracy: 0.9819 - 148ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0401 - accuracy: 0.9831 - 153ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0378 - accuracy: 0.9831 - 259ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0392 - accuracy: 0.9846 - 155ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0356 - accuracy: 0.9855 - 151ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0359 - accuracy: 0.9843 - 159ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0349 - accuracy: 0.9849 - 168ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0450 - accuracy: 0.9763 - 202ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.2319 - accuracy: 0.9321 - 608ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0521 - accuracy: 0.9739 - 158ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0490 - accuracy: 0.9745 - 156ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0442 - accuracy: 0.9801 - 158ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0446 - accuracy: 0.9792 - 154ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0430 - accuracy: 0.9804 - 154ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0427 - accuracy: 0.9792 - 152ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0398 - accuracy: 0.9801 - 151ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0377 - accuracy: 0.9858 - 150ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0354 - accuracy: 0.9858 - 151ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0344 - accuracy: 0.9881 - 182ms/epoch - 3ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.2225 - accuracy: 0.9306 - 661ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0515 - accuracy: 0.9783 - 150ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0454 - accuracy: 0.9778 - 164ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0442 - accuracy: 0.9798 - 153ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0410 - accuracy: 0.9822 - 154ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0398 - accuracy: 0.9849 - 215ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0376 - accuracy: 0.9849 - 226ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0371 - accuracy: 0.9852 - 214ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0366 - accuracy: 0.9828 - 190ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0360 - accuracy: 0.9849 - 153ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0337 - accuracy: 0.9858 - 203ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.4891 - accuracy: 0.8709 - 763ms/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.2676 - accuracy: 0.9053 - 168ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.1193 - accuracy: 0.9674 - 145ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0654 - accuracy: 0.9777 - 167ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0529 - accuracy: 0.9789 - 171ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0475 - accuracy: 0.9783 - 173ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0461 - accuracy: 0.9795 - 168ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0448 - accuracy: 0.9783 - 159ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0433 - accuracy: 0.9792 - 138ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0414 - accuracy: 0.9816 - 141ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0504 - accuracy: 0.9769 - 215ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.5417 - accuracy: 0.8321 - 613ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.2746 - accuracy: 0.8956 - 134ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.1356 - accuracy: 0.9499 - 134ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0738 - accuracy: 0.9721 - 130ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0567 - accuracy: 0.9792 - 130ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0510 - accuracy: 0.9789 - 132ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0480 - accuracy: 0.9804 - 131ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0463 - accuracy: 0.9798 - 131ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0456 - accuracy: 0.9795 - 135ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0454 - accuracy: 0.9786 - 132ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0425 - accuracy: 0.9834 - 185ms/epoch - 3ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.4056 - accuracy: 0.8914 - 612ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.1871 - accuracy: 0.9362 - 142ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.1078 - accuracy: 0.9626 - 133ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0697 - accuracy: 0.9754 - 144ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0580 - accuracy: 0.9780 - 135ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0535 - accuracy: 0.9786 - 135ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0516 - accuracy: 0.9789 - 129ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0492 - accuracy: 0.9795 - 133ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0476 - accuracy: 0.9795 - 131ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0469 - accuracy: 0.9786 - 132ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0453 - accuracy: 0.9792 - 185ms/epoch - 3ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.5020 - accuracy: 0.8401 - 640ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.1502 - accuracy: 0.9519 - 130ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0649 - accuracy: 0.9706 - 134ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0529 - accuracy: 0.9757 - 193ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0479 - accuracy: 0.9777 - 175ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0461 - accuracy: 0.9798 - 132ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0419 - accuracy: 0.9825 - 149ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0407 - accuracy: 0.9837 - 150ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0406 - accuracy: 0.9819 - 142ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0388 - accuracy: 0.9825 - 155ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0496 - accuracy: 0.9769 - 192ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.5528 - accuracy: 0.7754 - 701ms/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.2135 - accuracy: 0.9018 - 268ms/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0974 - accuracy: 0.9647 - 181ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0607 - accuracy: 0.9754 - 229ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0517 - accuracy: 0.9789 - 241ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0484 - accuracy: 0.9769 - 185ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0467 - accuracy: 0.9786 - 164ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0452 - accuracy: 0.9807 - 186ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0443 - accuracy: 0.9786 - 171ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0437 - accuracy: 0.9798 - 171ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0404 - accuracy: 0.9834 - 246ms/epoch - 5ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.4175 - accuracy: 0.8855 - 654ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.1467 - accuracy: 0.9427 - 134ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0630 - accuracy: 0.9742 - 134ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0521 - accuracy: 0.9780 - 130ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0479 - accuracy: 0.9792 - 129ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0461 - accuracy: 0.9795 - 133ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0456 - accuracy: 0.9789 - 160ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0439 - accuracy: 0.9813 - 153ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0444 - accuracy: 0.9807 - 140ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0443 - accuracy: 0.9798 - 161ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0410 - accuracy: 0.9828 - 195ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.4014 - accuracy: 0.8513 - 692ms/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0786 - accuracy: 0.9697 - 156ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0499 - accuracy: 0.9789 - 164ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0443 - accuracy: 0.9810 - 180ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0421 - accuracy: 0.9813 - 184ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0399 - accuracy: 0.9831 - 173ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0384 - accuracy: 0.9822 - 164ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0374 - accuracy: 0.9849 - 156ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0367 - accuracy: 0.9834 - 157ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0367 - accuracy: 0.9837 - 149ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0669 - accuracy: 0.9698 - 194ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.3535 - accuracy: 0.8944 - 695ms/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0768 - accuracy: 0.9712 - 170ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0493 - accuracy: 0.9780 - 166ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0456 - accuracy: 0.9792 - 165ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0444 - accuracy: 0.9783 - 170ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0450 - accuracy: 0.9795 - 149ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0441 - accuracy: 0.9792 - 167ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0430 - accuracy: 0.9819 - 166ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0413 - accuracy: 0.9813 - 145ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0413 - accuracy: 0.9810 - 142ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0366 - accuracy: 0.9864 - 195ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.2872 - accuracy: 0.9140 - 667ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0647 - accuracy: 0.9724 - 147ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0489 - accuracy: 0.9769 - 147ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0455 - accuracy: 0.9810 - 155ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0446 - accuracy: 0.9804 - 163ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0434 - accuracy: 0.9819 - 167ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0412 - accuracy: 0.9816 - 153ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0407 - accuracy: 0.9813 - 150ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0399 - accuracy: 0.9825 - 150ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0388 - accuracy: 0.9837 - 153ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0436 - accuracy: 0.9792 - 211ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.2757 - accuracy: 0.9000 - 697ms/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0472 - accuracy: 0.9792 - 167ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0435 - accuracy: 0.9810 - 161ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0399 - accuracy: 0.9819 - 160ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0372 - accuracy: 0.9840 - 165ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0381 - accuracy: 0.9834 - 151ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0355 - accuracy: 0.9855 - 158ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0357 - accuracy: 0.9840 - 169ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0333 - accuracy: 0.9858 - 157ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0312 - accuracy: 0.9872 - 164ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0445 - accuracy: 0.9804 - 198ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.2609 - accuracy: 0.9238 - 660ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0550 - accuracy: 0.9751 - 164ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0484 - accuracy: 0.9760 - 171ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0447 - accuracy: 0.9801 - 154ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0419 - accuracy: 0.9822 - 188ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0424 - accuracy: 0.9795 - 156ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0403 - accuracy: 0.9816 - 148ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0402 - accuracy: 0.9801 - 153ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0382 - accuracy: 0.9837 - 163ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0366 - accuracy: 0.9825 - 164ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0339 - accuracy: 0.9852 - 187ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.3070 - accuracy: 0.8974 - 681ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0532 - accuracy: 0.9780 - 174ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0480 - accuracy: 0.9786 - 154ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0449 - accuracy: 0.9810 - 149ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0414 - accuracy: 0.9825 - 151ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0395 - accuracy: 0.9819 - 153ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0364 - accuracy: 0.9843 - 171ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0363 - accuracy: 0.9855 - 173ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0360 - accuracy: 0.9852 - 163ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0338 - accuracy: 0.9875 - 176ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0424 - accuracy: 0.9798 - 189ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.1481 - accuracy: 0.9510 - 1s/epoch - 11ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0491 - accuracy: 0.9792 - 193ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0418 - accuracy: 0.9822 - 168ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0405 - accuracy: 0.9822 - 166ms/epoch - 2ms/step\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 - 0s - loss: 0.0357 - accuracy: 0.9864 - 171ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0355 - accuracy: 0.9843 - 179ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0327 - accuracy: 0.9884 - 186ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0280 - accuracy: 0.9884 - 172ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0257 - accuracy: 0.9911 - 168ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0219 - accuracy: 0.9920 - 169ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0300 - accuracy: 0.9899 - 193ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.1559 - accuracy: 0.9487 - 692ms/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0497 - accuracy: 0.9763 - 214ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0458 - accuracy: 0.9798 - 233ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0420 - accuracy: 0.9834 - 218ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0417 - accuracy: 0.9804 - 218ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0379 - accuracy: 0.9834 - 196ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0371 - accuracy: 0.9843 - 173ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0375 - accuracy: 0.9810 - 183ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0322 - accuracy: 0.9867 - 169ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0292 - accuracy: 0.9893 - 166ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0263 - accuracy: 0.9905 - 288ms/epoch - 5ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.1804 - accuracy: 0.9442 - 678ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0479 - accuracy: 0.9792 - 174ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0446 - accuracy: 0.9807 - 214ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0427 - accuracy: 0.9807 - 229ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0403 - accuracy: 0.9840 - 225ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0411 - accuracy: 0.9825 - 235ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0387 - accuracy: 0.9849 - 230ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0344 - accuracy: 0.9861 - 219ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0322 - accuracy: 0.9855 - 217ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0291 - accuracy: 0.9887 - 181ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0281 - accuracy: 0.9911 - 202ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "158/158 - 1s - loss: 0.1381 - accuracy: 0.9543 - 710ms/epoch - 4ms/step\n",
      "Epoch 2/10\n",
      "158/158 - 0s - loss: 0.0446 - accuracy: 0.9802 - 243ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "158/158 - 0s - loss: 0.0443 - accuracy: 0.9820 - 276ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "158/158 - 0s - loss: 0.0405 - accuracy: 0.9824 - 235ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "158/158 - 0s - loss: 0.0357 - accuracy: 0.9840 - 326ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "158/158 - 0s - loss: 0.0318 - accuracy: 0.9867 - 246ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "158/158 - 0s - loss: 0.0261 - accuracy: 0.9905 - 296ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "158/158 - 0s - loss: 0.0229 - accuracy: 0.9931 - 242ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "158/158 - 0s - loss: 0.0220 - accuracy: 0.9923 - 254ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "158/158 - 0s - loss: 0.0162 - accuracy: 0.9955 - 265ms/epoch - 2ms/step\n",
      "Best: 0.990506 using {'num_neurons': 128, 'num_layers': 2}\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "\n",
    "# Define the neural network model\n",
    "def create_model(num_layers=1, num_neurons=10):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_neurons, input_dim=X_train.shape[1], activation='relu'))\n",
    "    for i in range(num_layers):\n",
    "        model.add(Dense(num_neurons, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create a KerasClassifier with fixed batch_size and epochs\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, verbose=2)\n",
    "\n",
    "# Define the hyperparameter distribution to search\n",
    "param_dist = {\n",
    "    'num_layers': [1,2,3],\n",
    "    'num_neurons': [8,32,64,128, 256],\n",
    "}\n",
    "\n",
    "# Perform randomized search\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, cv=3, n_iter=10)\n",
    "random_search_result = random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the results\n",
    "print(\"Best: %f using %s\" % (random_search_result.best_score_, random_search_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fc8e51fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best: 0.990506 using {'num_neurons': 128, 'num_layers': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7209603",
   "metadata": {},
   "source": [
    "## Training the best architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a92165e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "158/158 - 1s - loss: 0.1460 - accuracy: 0.9502 - 668ms/epoch - 4ms/step\n",
      "Epoch 2/50\n",
      "158/158 - 0s - loss: 0.0458 - accuracy: 0.9808 - 271ms/epoch - 2ms/step\n",
      "Epoch 3/50\n",
      "158/158 - 0s - loss: 0.0431 - accuracy: 0.9820 - 314ms/epoch - 2ms/step\n",
      "Epoch 4/50\n",
      "158/158 - 0s - loss: 0.0401 - accuracy: 0.9828 - 239ms/epoch - 2ms/step\n",
      "Epoch 5/50\n",
      "158/158 - 0s - loss: 0.0372 - accuracy: 0.9838 - 234ms/epoch - 1ms/step\n",
      "Epoch 6/50\n",
      "158/158 - 0s - loss: 0.0366 - accuracy: 0.9850 - 240ms/epoch - 2ms/step\n",
      "Epoch 7/50\n",
      "158/158 - 0s - loss: 0.0325 - accuracy: 0.9858 - 288ms/epoch - 2ms/step\n",
      "Epoch 8/50\n",
      "158/158 - 0s - loss: 0.0285 - accuracy: 0.9881 - 244ms/epoch - 2ms/step\n",
      "Epoch 9/50\n",
      "158/158 - 0s - loss: 0.0247 - accuracy: 0.9917 - 246ms/epoch - 2ms/step\n",
      "Epoch 10/50\n",
      "158/158 - 0s - loss: 0.0191 - accuracy: 0.9941 - 243ms/epoch - 2ms/step\n",
      "Epoch 11/50\n",
      "158/158 - 0s - loss: 0.0161 - accuracy: 0.9955 - 236ms/epoch - 1ms/step\n",
      "Epoch 12/50\n",
      "158/158 - 0s - loss: 0.0181 - accuracy: 0.9945 - 238ms/epoch - 2ms/step\n",
      "Epoch 13/50\n",
      "158/158 - 0s - loss: 0.0142 - accuracy: 0.9955 - 246ms/epoch - 2ms/step\n",
      "Epoch 14/50\n",
      "158/158 - 0s - loss: 0.0123 - accuracy: 0.9960 - 273ms/epoch - 2ms/step\n",
      "Epoch 15/50\n",
      "158/158 - 0s - loss: 0.0097 - accuracy: 0.9970 - 269ms/epoch - 2ms/step\n",
      "Epoch 16/50\n",
      "158/158 - 0s - loss: 0.0135 - accuracy: 0.9949 - 288ms/epoch - 2ms/step\n",
      "Epoch 17/50\n",
      "158/158 - 0s - loss: 0.0092 - accuracy: 0.9972 - 265ms/epoch - 2ms/step\n",
      "Epoch 18/50\n",
      "158/158 - 0s - loss: 0.0072 - accuracy: 0.9974 - 233ms/epoch - 1ms/step\n",
      "Epoch 19/50\n",
      "158/158 - 0s - loss: 0.0108 - accuracy: 0.9960 - 246ms/epoch - 2ms/step\n",
      "Epoch 20/50\n",
      "158/158 - 0s - loss: 0.0054 - accuracy: 0.9986 - 298ms/epoch - 2ms/step\n",
      "Epoch 21/50\n",
      "158/158 - 0s - loss: 0.0127 - accuracy: 0.9962 - 283ms/epoch - 2ms/step\n",
      "Epoch 22/50\n",
      "158/158 - 0s - loss: 0.0121 - accuracy: 0.9968 - 243ms/epoch - 2ms/step\n",
      "Epoch 23/50\n",
      "158/158 - 0s - loss: 0.0047 - accuracy: 0.9976 - 319ms/epoch - 2ms/step\n",
      "Epoch 24/50\n",
      "158/158 - 0s - loss: 0.0035 - accuracy: 0.9986 - 328ms/epoch - 2ms/step\n",
      "Epoch 25/50\n",
      "158/158 - 0s - loss: 0.0025 - accuracy: 0.9992 - 273ms/epoch - 2ms/step\n",
      "Epoch 26/50\n",
      "158/158 - 0s - loss: 0.0050 - accuracy: 0.9982 - 238ms/epoch - 2ms/step\n",
      "Epoch 27/50\n",
      "158/158 - 0s - loss: 0.0014 - accuracy: 0.9996 - 278ms/epoch - 2ms/step\n",
      "Epoch 28/50\n",
      "158/158 - 0s - loss: 0.0031 - accuracy: 0.9986 - 285ms/epoch - 2ms/step\n",
      "Epoch 29/50\n",
      "158/158 - 0s - loss: 0.0043 - accuracy: 0.9984 - 267ms/epoch - 2ms/step\n",
      "Epoch 30/50\n",
      "158/158 - 0s - loss: 0.0027 - accuracy: 0.9992 - 234ms/epoch - 1ms/step\n",
      "Epoch 31/50\n",
      "158/158 - 0s - loss: 0.0012 - accuracy: 0.9998 - 233ms/epoch - 1ms/step\n",
      "Epoch 32/50\n",
      "158/158 - 0s - loss: 5.4445e-04 - accuracy: 1.0000 - 289ms/epoch - 2ms/step\n",
      "Epoch 33/50\n",
      "158/158 - 0s - loss: 4.7526e-04 - accuracy: 1.0000 - 286ms/epoch - 2ms/step\n",
      "Epoch 34/50\n",
      "158/158 - 0s - loss: 7.2628e-04 - accuracy: 0.9996 - 248ms/epoch - 2ms/step\n",
      "Epoch 35/50\n",
      "158/158 - 0s - loss: 0.0125 - accuracy: 0.9951 - 232ms/epoch - 1ms/step\n",
      "Epoch 36/50\n",
      "158/158 - 0s - loss: 0.0026 - accuracy: 0.9992 - 231ms/epoch - 1ms/step\n",
      "Epoch 37/50\n",
      "158/158 - 0s - loss: 0.0023 - accuracy: 0.9992 - 230ms/epoch - 1ms/step\n",
      "Epoch 38/50\n",
      "158/158 - 0s - loss: 8.7998e-04 - accuracy: 0.9998 - 230ms/epoch - 1ms/step\n",
      "Epoch 39/50\n",
      "158/158 - 0s - loss: 5.0678e-04 - accuracy: 0.9998 - 232ms/epoch - 1ms/step\n",
      "Epoch 40/50\n",
      "158/158 - 0s - loss: 5.0906e-04 - accuracy: 0.9998 - 233ms/epoch - 1ms/step\n",
      "Epoch 41/50\n",
      "158/158 - 0s - loss: 0.0011 - accuracy: 0.9996 - 246ms/epoch - 2ms/step\n",
      "Epoch 42/50\n",
      "158/158 - 0s - loss: 0.0017 - accuracy: 0.9998 - 288ms/epoch - 2ms/step\n",
      "Epoch 43/50\n",
      "158/158 - 0s - loss: 5.5698e-04 - accuracy: 0.9998 - 291ms/epoch - 2ms/step\n",
      "Epoch 44/50\n",
      "158/158 - 0s - loss: 0.0038 - accuracy: 0.9984 - 253ms/epoch - 2ms/step\n",
      "Epoch 45/50\n",
      "158/158 - 0s - loss: 0.0115 - accuracy: 0.9968 - 243ms/epoch - 2ms/step\n",
      "Epoch 46/50\n",
      "158/158 - 0s - loss: 0.0020 - accuracy: 0.9994 - 240ms/epoch - 2ms/step\n",
      "Epoch 47/50\n",
      "158/158 - 0s - loss: 0.0103 - accuracy: 0.9968 - 239ms/epoch - 2ms/step\n",
      "Epoch 48/50\n",
      "158/158 - 0s - loss: 0.0015 - accuracy: 0.9996 - 292ms/epoch - 2ms/step\n",
      "Epoch 49/50\n",
      "158/158 - 0s - loss: 9.7666e-04 - accuracy: 0.9996 - 319ms/epoch - 2ms/step\n",
      "Epoch 50/50\n",
      "158/158 - 0s - loss: 4.0344e-04 - accuracy: 1.0000 - 306ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f98a65135b0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "best_num_layers = random_search_result.best_params_[\"num_layers\"]\n",
    "best_num_neurons = random_search_result.best_params_[\"num_neurons\"]\n",
    "model = create_model(num_layers=best_num_layers, num_neurons=best_num_neurons)\n",
    "model.fit(X_train, y_train, epochs=50, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "88da9caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 1ms/step\n",
      "[[1129    4]\n",
      " [   1  131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1133\n",
      "           1       0.97      0.99      0.98       132\n",
      "\n",
      "    accuracy                           1.00      1265\n",
      "   macro avg       0.98      0.99      0.99      1265\n",
      "weighted avg       1.00      1.00      1.00      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use the trained classifier to predict the class labels for the test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.round(y_pred)\n",
    "# Evaluate the classifier's performance on the test data\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "30a526d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0101 - accuracy: 0.9960\n",
      "Accuracy: 0.9960\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the testing set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "\n",
    "# Print the accuracy without rounding\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219d8c0e",
   "metadata": {},
   "source": [
    "Both SVM and Neural Network performs with a similar accuaracy. Neural network performs slightly better than non-linear SVM. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18df1afa",
   "metadata": {},
   "source": [
    "# Variable Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95631e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = data[['Bidder_Tendency', 'Successive_Outbidding', 'Last_Bidding',\n",
    "       'Winning_Ratio']]\n",
    "y = data['Class']\n",
    "X_train_sl_ft_1, X_test_sl_ft_1, y_train_sl_ft_1, y_test_sl_ft_1 = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d514fbe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4958bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "def create_model_(num_layers=1, num_neurons=10):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_neurons, input_dim=X_train_.shape[1], activation='relu'))\n",
    "    for i in range(num_layers):\n",
    "        model.add(Dense(num_neurons, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaaf90a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = create_model_(num_layers=2, num_neurons=64)\n",
    "model.fit(X_train_sl_ft_1, y_train_sl_ft_1, epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f76960",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Use the trained classifier to predict the class labels for the test data\n",
    "y_pred_ = model.predict(X_test_sl_ft_1)\n",
    "y_pred_ = np.round(y_pred_sl_ft_1)\n",
    "# Evaluate the classifier's performance on the test data\n",
    "print(confusion_matrix(y_test_sl_ft_1, y_pred_sl_ft_1))\n",
    "print(classification_report(y_test_sl_ft_1, y_pred_sl_ft_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5529b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: train ELM on selected variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1c650e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = data[['Bidder_Tendency', 'Bidding_Ratio', 'Successive_Outbidding', 'Winning_Ratio']]\n",
    "y = data['Class']\n",
    "X_train_sl_ft_2, X_test_sl_ft_2, y_train_sl_ft_2, y_test_sl_ft_2 = train_test_split(X, y, test_size=0.2)\n",
    "model = create_model_(num_layers=2, num_neurons=64)\n",
    "model.fit(X_train_sl_ft_2, y_train_sl_ft_2, epochs=50, verbose=2)\n",
    "\n",
    "# Use the trained classifier to predict the class labels for the test data\n",
    "y_pred_ = model.predict(X_test_sl_ft_2)\n",
    "y_pred_ = np.round(y_pred_sl_ft_2)\n",
    "# Evaluate the classifier's performance on the test data\n",
    "print(confusion_matrix(y_test_sl_ft_2, y_pred_sl_ft_2))\n",
    "print(classification_report(y_test_sl_ft_2, y_pred_sl_ft_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2605eabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained classifier to predict the class labels for the test data\n",
    "y_pred_sl_ft_2 = model.predict(X_test_sl_ft_2)\n",
    "y_pred_sl_ft_2 = np.round(y_pred_sl_ft_2)\n",
    "# Evaluate the classifier's performance on the test data\n",
    "print(confusion_matrix(y_test_sl_ft_2, y_pred_sl_ft_2))\n",
    "print(classification_report(y_test_sl_ft_2, y_pred_sl_ft_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187fc983",
   "metadata": {},
   "source": [
    "Both feature selections provide similar accuracies. \n",
    "But we are going to conisder Lasso feature selection method for our case, because Lasso is linear and uses L1 regularization to shrink coefficients of the features towards zero which can also prevent the problem of overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc77c67",
   "metadata": {},
   "source": [
    "## Using the best model from part 2 and part 3 on the selected features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d84905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Selected features : ['Bidder_Tendency', 'Successive_Outbidding', 'Last_Bidding', 'Winning_Ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc77f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = data[['Bidder_Tendency', 'Successive_Outbidding', 'Last_Bidding',\n",
    "       'Winning_Ratio']]\n",
    "y = data['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccc9986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST MODEL FROM PART - 2 (Random Forest)\n",
    "# Best hyperparameters:  \n",
    "# {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
    "\n",
    "# Define the random forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=20)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(acc_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7394ec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "def create_model_(num_layers=1, num_neurons=10):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_neurons, input_dim=X_train_.shape[1], activation='relu'))\n",
    "    for i in range(num_layers):\n",
    "        model.add(Dense(num_neurons, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model_(num_layers=2, num_neurons=64)\n",
    "model.fit(X_train, y_train, epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98abd7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the testing set\n",
    "loss, accuracy_nn = model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634f72f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the accuracy without rounding\n",
    "print(\"Accuracy of the best part 2 model (Rf) on selected features : {:.4f}\".format(acc_rf))\n",
    "print(\"Accuracy of the best part 3 model (NN) on selected features: {:.4f}\".format(accuracy_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49e8056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100)\n",
    "\n",
    "sfs = SFS(rf,\n",
    "          k_features=(1, X.shape[1]),\n",
    "          forward=True,\n",
    "          floating=True,\n",
    "          scoring='accuracy',\n",
    "          cv=5,\n",
    "          n_jobs=-1)\n",
    "\n",
    "sfs = sfs.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Get the selected column names\n",
    "selected_columns = X.columns[list(sfs.k_feature_idx_)]\n",
    "\n",
    "# Print the selected column names\n",
    "print(\"Selected features (RF):\", selected_columns)\n",
    "\n",
    "# Print the best score\n",
    "print(\"Best score (RF):\", sfs.k_score_)\n",
    "\n",
    "# Transform X to contain only the selected features\n",
    "X_selected_rf = sfs.transform(X)\n",
    "\n",
    "# Train RF and NN models with selected features\n",
    "rf.fit(X_selected_rf, y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae30629",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "X = X_train\n",
    "y = y_train\n",
    "\n",
    "# Scale data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Define the neural network model\n",
    "nn_model = MLPClassifier(hidden_layer_sizes=(64, 64), max_iter=100, solver='adam', \n",
    "                         verbose=0,  random_state=42, tol=0.0001)\n",
    "\n",
    "# Define the Bi-directional Elimination wrapper method\n",
    "sfs = SFS(nn_model, k_features=(1, X.shape[1]), forward=True, floating=True, verbose=2, scoring='accuracy', cv=5)\n",
    "\n",
    "# Perform feature selection using the wrapper method\n",
    "sfs = sfs.fit(X, y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = data.drop(['Class', 'Bidder_ID'], axis=1)\n",
    "# Get the selected column names\n",
    "selected_columns = X.columns[list(sfs.k_feature_idx_)]\n",
    "\n",
    "# Print the selected column names\n",
    "print(\"Selected features:\", selected_columns)\n",
    "\n",
    "# Train neural network model with selected features\n",
    "X_selected = sfs.transform(X_train)\n",
    "nn_model.fit(X_selected, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d35172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = data.drop(['Class', 'Bidder_ID'], axis=1)\n",
    "y = data['Class']\n",
    "selected_columns = X.columns[list(sfs.k_feature_idx_)]\n",
    "print(selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f55e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the accuracy without rounding\n",
    "print(\"Accuracy of the best part 2 model (Rf) on selected features : {:.4f}\".format(acc_rf))\n",
    "print(\"Accuracy of the best part 3 model (NN) on selected features: {:.4f}\".format(accuracy_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9160168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: report test accuracies for both models on the given selected feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d011257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
