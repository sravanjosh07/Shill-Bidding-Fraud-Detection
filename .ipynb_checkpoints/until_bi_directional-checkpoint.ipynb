{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6934bb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "import warnings\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from hpelm import ELM\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "24234961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bidder_ID</th>\n",
       "      <th>Bidder_Tendency</th>\n",
       "      <th>Bidding_Ratio</th>\n",
       "      <th>Successive_Outbidding</th>\n",
       "      <th>Last_Bidding</th>\n",
       "      <th>Auction_Bids</th>\n",
       "      <th>Starting_Price_Average</th>\n",
       "      <th>Early_Bidding</th>\n",
       "      <th>Winning_Ratio</th>\n",
       "      <th>Auction_Duration</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Auction_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>_***i</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>g***r</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>t***p</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>7***n</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>0.097477</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>z***z</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Bidder_ID  Bidder_Tendency  Bidding_Ratio  Successive_Outbidding  \\\n",
       "Auction_ID                                                                    \n",
       "732            _***i         0.200000       0.400000                    0.0   \n",
       "732            g***r         0.024390       0.200000                    0.0   \n",
       "732            t***p         0.142857       0.200000                    0.0   \n",
       "732            7***n         0.100000       0.200000                    0.0   \n",
       "900            z***z         0.051282       0.222222                    0.0   \n",
       "\n",
       "            Last_Bidding  Auction_Bids  Starting_Price_Average  Early_Bidding  \\\n",
       "Auction_ID                                                                      \n",
       "732             0.000028           0.0                0.993593       0.000028   \n",
       "732             0.013123           0.0                0.993593       0.013123   \n",
       "732             0.003042           0.0                0.993593       0.003042   \n",
       "732             0.097477           0.0                0.993593       0.097477   \n",
       "900             0.001318           0.0                0.000000       0.001242   \n",
       "\n",
       "            Winning_Ratio  Auction_Duration  Class  \n",
       "Auction_ID                                          \n",
       "732              0.666667          0.444444      0  \n",
       "732              0.944444          0.444444      0  \n",
       "732              1.000000          0.444444      0  \n",
       "732              1.000000          0.444444      0  \n",
       "900              0.500000          0.666667      0  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Group_14_data_cleaned.csv\", index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f0f1a3f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5646\n",
       "1     675\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4f8d6584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = data.drop(['Class', 'Bidder_ID'], axis=1)\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2652f7",
   "metadata": {},
   "source": [
    "## ELM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0b19eead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1119   14]\n",
      " [   1  131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      1133\n",
      "           1       0.90      0.99      0.95       132\n",
      "\n",
      "    accuracy                           0.99      1265\n",
      "   macro avg       0.95      0.99      0.97      1265\n",
      "weighted avg       0.99      0.99      0.99      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert input data to numpy arrays\n",
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "X_test = X_test.values\n",
    "y_test = y_test.values\n",
    "\n",
    "# Initialize the ELM model with the desired parameters\n",
    "model = ELM(X_train.shape[1], 1, classification=\"c\", batch=10, accelerator=\"cpu\", precision=\"single\")\n",
    "\n",
    "model.add_neurons(256, \"tanh\")\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.train(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.round(y_pred)\n",
    "# Evaluate the classifier's performance on the test data\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "05a2a432",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: nan using {'n_hidden': 32, 'activation': 'tanh'}\n",
      "Best parameters:  {'n_hidden': 32, 'activation': 'tanh'}\n",
      "Best score:  nan\n"
     ]
    }
   ],
   "source": [
    "class ELMClassifier:\n",
    "    def __init__(self, n_hidden=10, activation=\"tanh\", batch=10):\n",
    "        self.n_hidden = n_hidden\n",
    "        self.activation = activation\n",
    "        self.batch = batch\n",
    "        self.elm = ELM(inputs=X_train.shape[1], outputs=1, classification=\"c\", batch=batch)\n",
    "        self.elm.add_neurons(n_hidden, activation)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.elm.train(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.elm.predict(X)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y, y_pred)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {'n_hidden': self.n_hidden, 'activation': self.activation, 'batch': self.batch}\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for param, value in params.items():\n",
    "            setattr(self, param, value)\n",
    "        return self\n",
    "\n",
    "\n",
    "# Define the hyperparameters and their ranges\n",
    "param_grid = {\n",
    "    'n_hidden': [32, 64, 128],\n",
    "    'activation': ['tanh']\n",
    "}\n",
    "\n",
    "# elm_classifier = ELMClassifier()\n",
    "# Initialize the random search object\n",
    "elm_random = RandomizedSearchCV(estimator= ELMClassifier(), param_distributions=param_grid, n_iter=10, cv=5, random_state=42)\n",
    "\n",
    "# Fit the random search object to the training data\n",
    "random_search_result = elm_random.fit(X_train, y_train)\n",
    "\n",
    "# Print the results\n",
    "print(\"Best: %f using %s\" % (random_search_result.best_score_, random_search_result.best_params_))\n",
    "\n",
    "# Print the best parameters and corresponding score\n",
    "print(\"Best parameters: \", random_search_result.best_params_)\n",
    "print(\"Best score: \", random_search_result.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dcc0a4",
   "metadata": {},
   "source": [
    "## SVM with Linear Kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f8a8c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'C': 2.209602254061174, 'gamma': 3.935350823412439, 'kernel': 'linear'}\n",
      "Accuracy score:  0.9829980312538452\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "# RANDOM SEARCH FOR 20 COMBINATIONS OF PARAMETERS\n",
    "rand_list = {\"C\": stats.uniform(2, 10),\n",
    "\"gamma\": stats.uniform(0.1, 5),\n",
    "'kernel': ['linear']}\n",
    "rand_search = RandomizedSearchCV(mdl, param_distributions = rand_list, n_iter = 50, n_jobs = 4, cv = 3, random_state = 2017, scoring = auc) \n",
    "rand_search.fit(X_train, y_train) \n",
    "# rand_search.cv_results_\n",
    "\n",
    "# Print the best hyperparameters and the corresponding accuracy score\n",
    "print(\"Best hyperparameters: \", rand_search.best_params_)\n",
    "print(\"Accuracy score: \", rand_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b139440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1110   21]\n",
      " [   3  131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      1131\n",
      "           1       0.86      0.98      0.92       134\n",
      "\n",
      "    accuracy                           0.98      1265\n",
      "   macro avg       0.93      0.98      0.95      1265\n",
      "weighted avg       0.98      0.98      0.98      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the best hyperparameters to create a new SVM model\n",
    "best_svm_model = SVC(C=rand_search.best_params_['C'], kernel=rand_search.best_params_['kernel'], gamma=rand_search.best_params_['gamma'])\n",
    "\n",
    "# Train the new SVM model using the training data\n",
    "best_svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained classifier to predict the class labels for the test data\n",
    "y_pred = best_svm_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluate the classifier's performance on the test data\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d99d09",
   "metadata": {},
   "source": [
    "## SVM with non linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8705db2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'C': 9.087699346650997, 'gamma': 1.0163457603417565, 'kernel': 'rbf'}\n",
      "Accuracy score:  0.9886417589006565\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "# RANDOM SEARCH FOR 20 COMBINATIONS OF PARAMETERS\n",
    "rand_list = {\"C\": stats.uniform(2, 10),\n",
    "\"gamma\": stats.uniform(0.1, 1),\n",
    "'kernel': ['poly', 'rbf']}\n",
    "rand_search = RandomizedSearchCV(mdl, param_distributions = rand_list, n_iter = 50, n_jobs = 4, cv = 3, random_state = 2017, scoring = auc) \n",
    "rand_search.fit(X_train, y_train) \n",
    "# rand_search.cv_results_\n",
    "\n",
    "# Print the best hyperparameters and the corresponding accuracy score\n",
    "print(\"Best hyperparameters: \", rand_search.best_params_)\n",
    "print(\"Accuracy score: \", rand_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8bce29c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1126    5]\n",
      " [   5  129]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1131\n",
      "           1       0.96      0.96      0.96       134\n",
      "\n",
      "    accuracy                           0.99      1265\n",
      "   macro avg       0.98      0.98      0.98      1265\n",
      "weighted avg       0.99      0.99      0.99      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the best hyperparameters to create a new SVM model\n",
    "best_svm_model = SVC(C=rand_search.best_params_['C'], kernel=rand_search.best_params_['kernel'], gamma=rand_search.best_params_['gamma'])\n",
    "\n",
    "# Train the new SVM model using the training data\n",
    "best_svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained classifier to predict the class labels for the test data\n",
    "y_pred = best_svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier's performance on the test data\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2754a225",
   "metadata": {},
   "source": [
    "## Training a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53ed735d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jx/rs472zns1ds_9lgk5hq47qz80000gp/T/ipykernel_11317/4130843927.py:20: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, batch_size=32, epochs=10, verbose=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 - 1s - loss: 0.4276 - accuracy: 0.8905 - 710ms/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.1264 - accuracy: 0.9561 - 167ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0642 - accuracy: 0.9736 - 147ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0554 - accuracy: 0.9774 - 139ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0512 - accuracy: 0.9789 - 143ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0475 - accuracy: 0.9786 - 169ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0472 - accuracy: 0.9792 - 176ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0462 - accuracy: 0.9786 - 176ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0448 - accuracy: 0.9783 - 174ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0436 - accuracy: 0.9789 - 162ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0325 - accuracy: 0.9840 - 202ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.3939 - accuracy: 0.8941 - 1s/epoch - 11ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0955 - accuracy: 0.9665 - 142ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0531 - accuracy: 0.9763 - 138ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0474 - accuracy: 0.9769 - 140ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0440 - accuracy: 0.9789 - 144ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0440 - accuracy: 0.9769 - 148ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0427 - accuracy: 0.9786 - 140ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0410 - accuracy: 0.9801 - 139ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0413 - accuracy: 0.9792 - 153ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0407 - accuracy: 0.9769 - 138ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0412 - accuracy: 0.9834 - 196ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.4196 - accuracy: 0.8905 - 734ms/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.1326 - accuracy: 0.9427 - 177ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0575 - accuracy: 0.9786 - 177ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0503 - accuracy: 0.9783 - 168ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0449 - accuracy: 0.9825 - 152ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0429 - accuracy: 0.9810 - 147ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0412 - accuracy: 0.9834 - 162ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0386 - accuracy: 0.9837 - 180ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0392 - accuracy: 0.9831 - 144ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0379 - accuracy: 0.9816 - 141ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0531 - accuracy: 0.9751 - 198ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.4013 - accuracy: 0.8908 - 690ms/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.1318 - accuracy: 0.9472 - 176ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0630 - accuracy: 0.9697 - 164ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0554 - accuracy: 0.9742 - 208ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0509 - accuracy: 0.9757 - 177ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0489 - accuracy: 0.9757 - 166ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0476 - accuracy: 0.9783 - 164ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0477 - accuracy: 0.9763 - 167ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0454 - accuracy: 0.9774 - 167ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0462 - accuracy: 0.9763 - 162ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0346 - accuracy: 0.9798 - 191ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.3876 - accuracy: 0.8689 - 707ms/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0889 - accuracy: 0.9629 - 146ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0540 - accuracy: 0.9721 - 148ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0476 - accuracy: 0.9754 - 147ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0439 - accuracy: 0.9789 - 147ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0425 - accuracy: 0.9763 - 146ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0401 - accuracy: 0.9816 - 143ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0399 - accuracy: 0.9775 - 142ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0402 - accuracy: 0.9798 - 150ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0386 - accuracy: 0.9807 - 166ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0434 - accuracy: 0.9810 - 221ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.3757 - accuracy: 0.8870 - 637ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.1174 - accuracy: 0.9617 - 148ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0599 - accuracy: 0.9721 - 145ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0473 - accuracy: 0.9804 - 144ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0439 - accuracy: 0.9783 - 161ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0402 - accuracy: 0.9825 - 165ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0391 - accuracy: 0.9828 - 167ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0379 - accuracy: 0.9825 - 166ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0366 - accuracy: 0.9825 - 145ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0363 - accuracy: 0.9852 - 266ms/epoch - 3ms/step\n",
      "53/53 - 0s - loss: 0.0476 - accuracy: 0.9763 - 196ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.4126 - accuracy: 0.8923 - 803ms/epoch - 8ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.1361 - accuracy: 0.9525 - 195ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0688 - accuracy: 0.9668 - 185ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0563 - accuracy: 0.9736 - 184ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0517 - accuracy: 0.9739 - 184ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0492 - accuracy: 0.9760 - 173ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0471 - accuracy: 0.9766 - 164ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0467 - accuracy: 0.9777 - 151ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0457 - accuracy: 0.9769 - 138ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0451 - accuracy: 0.9769 - 142ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0373 - accuracy: 0.9834 - 199ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.4919 - accuracy: 0.8419 - 789ms/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.1907 - accuracy: 0.9300 - 168ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0748 - accuracy: 0.9665 - 144ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0581 - accuracy: 0.9742 - 131ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0538 - accuracy: 0.9739 - 136ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0503 - accuracy: 0.9766 - 131ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0468 - accuracy: 0.9792 - 133ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0453 - accuracy: 0.9780 - 131ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0446 - accuracy: 0.9801 - 155ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0431 - accuracy: 0.9789 - 132ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0490 - accuracy: 0.9739 - 185ms/epoch - 3ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.4447 - accuracy: 0.8796 - 617ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.1408 - accuracy: 0.9585 - 131ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0599 - accuracy: 0.9739 - 131ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0465 - accuracy: 0.9786 - 129ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0420 - accuracy: 0.9819 - 130ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0397 - accuracy: 0.9819 - 130ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0372 - accuracy: 0.9813 - 128ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0368 - accuracy: 0.9855 - 127ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0366 - accuracy: 0.9849 - 135ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0361 - accuracy: 0.9867 - 131ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0638 - accuracy: 0.9763 - 184ms/epoch - 3ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.5241 - accuracy: 0.8923 - 613ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.3072 - accuracy: 0.8923 - 128ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.2095 - accuracy: 0.8923 - 127ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.1427 - accuracy: 0.8923 - 127ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.1084 - accuracy: 0.9496 - 128ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0797 - accuracy: 0.9730 - 126ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0628 - accuracy: 0.9745 - 125ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0552 - accuracy: 0.9777 - 128ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0515 - accuracy: 0.9777 - 124ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0493 - accuracy: 0.9798 - 124ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0366 - accuracy: 0.9822 - 193ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.5351 - accuracy: 0.8781 - 611ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.3473 - accuracy: 0.8944 - 126ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.1810 - accuracy: 0.9436 - 126ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0866 - accuracy: 0.9650 - 127ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0614 - accuracy: 0.9691 - 125ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0526 - accuracy: 0.9700 - 126ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0488 - accuracy: 0.9748 - 126ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0460 - accuracy: 0.9733 - 127ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0438 - accuracy: 0.9736 - 129ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0427 - accuracy: 0.9772 - 124ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0480 - accuracy: 0.9757 - 188ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.5147 - accuracy: 0.8428 - 658ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.2406 - accuracy: 0.8923 - 125ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.1557 - accuracy: 0.8923 - 129ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.1151 - accuracy: 0.9252 - 125ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0842 - accuracy: 0.9742 - 125ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0628 - accuracy: 0.9769 - 129ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0552 - accuracy: 0.9780 - 128ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0508 - accuracy: 0.9810 - 124ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0484 - accuracy: 0.9816 - 126ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0477 - accuracy: 0.9816 - 125ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0598 - accuracy: 0.9745 - 193ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.2343 - accuracy: 0.9240 - 637ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0547 - accuracy: 0.9721 - 144ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0476 - accuracy: 0.9780 - 145ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0456 - accuracy: 0.9789 - 144ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0448 - accuracy: 0.9783 - 145ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0427 - accuracy: 0.9798 - 143ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0414 - accuracy: 0.9807 - 150ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0397 - accuracy: 0.9822 - 147ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0398 - accuracy: 0.9816 - 146ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0368 - accuracy: 0.9828 - 144ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0290 - accuracy: 0.9852 - 183ms/epoch - 3ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.2494 - accuracy: 0.9163 - 623ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0521 - accuracy: 0.9772 - 144ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0424 - accuracy: 0.9801 - 142ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0435 - accuracy: 0.9786 - 142ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0382 - accuracy: 0.9828 - 146ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0379 - accuracy: 0.9801 - 141ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0373 - accuracy: 0.9801 - 145ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0371 - accuracy: 0.9816 - 143ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0361 - accuracy: 0.9813 - 143ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0356 - accuracy: 0.9825 - 150ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0406 - accuracy: 0.9828 - 212ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.2424 - accuracy: 0.9282 - 658ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0457 - accuracy: 0.9807 - 144ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0415 - accuracy: 0.9807 - 160ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0377 - accuracy: 0.9819 - 162ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0378 - accuracy: 0.9828 - 163ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0350 - accuracy: 0.9837 - 165ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0346 - accuracy: 0.9843 - 149ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0363 - accuracy: 0.9831 - 144ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0333 - accuracy: 0.9849 - 149ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0387 - accuracy: 0.9825 - 163ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0465 - accuracy: 0.9786 - 210ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.3913 - accuracy: 0.8923 - 678ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.1763 - accuracy: 0.8923 - 129ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.1174 - accuracy: 0.8923 - 130ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.1025 - accuracy: 0.9157 - 129ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0960 - accuracy: 0.9757 - 142ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0916 - accuracy: 0.9789 - 153ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0893 - accuracy: 0.9766 - 137ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0861 - accuracy: 0.9769 - 184ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0837 - accuracy: 0.9772 - 173ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0812 - accuracy: 0.9772 - 169ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0741 - accuracy: 0.9816 - 233ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.4891 - accuracy: 0.8926 - 744ms/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.2431 - accuracy: 0.8944 - 169ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.1360 - accuracy: 0.9318 - 153ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0623 - accuracy: 0.9798 - 142ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0474 - accuracy: 0.9801 - 134ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0440 - accuracy: 0.9789 - 139ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0423 - accuracy: 0.9804 - 136ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0413 - accuracy: 0.9804 - 136ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0399 - accuracy: 0.9816 - 140ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0388 - accuracy: 0.9831 - 134ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0459 - accuracy: 0.9792 - 198ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.5045 - accuracy: 0.8926 - 685ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.2640 - accuracy: 0.8923 - 131ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.1063 - accuracy: 0.9475 - 130ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0573 - accuracy: 0.9795 - 130ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0480 - accuracy: 0.9822 - 132ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0445 - accuracy: 0.9819 - 131ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0423 - accuracy: 0.9807 - 131ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0413 - accuracy: 0.9816 - 142ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0401 - accuracy: 0.9819 - 128ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0395 - accuracy: 0.9828 - 133ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0539 - accuracy: 0.9739 - 193ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.3102 - accuracy: 0.9089 - 592ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0668 - accuracy: 0.9709 - 137ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0502 - accuracy: 0.9789 - 138ms/epoch - 1ms/step\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 - 0s - loss: 0.0477 - accuracy: 0.9769 - 137ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0482 - accuracy: 0.9783 - 140ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0441 - accuracy: 0.9786 - 138ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0428 - accuracy: 0.9804 - 142ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0427 - accuracy: 0.9810 - 138ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0420 - accuracy: 0.9804 - 136ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0417 - accuracy: 0.9801 - 137ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0332 - accuracy: 0.9822 - 184ms/epoch - 3ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.3244 - accuracy: 0.9033 - 662ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0652 - accuracy: 0.9686 - 142ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0487 - accuracy: 0.9751 - 138ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0423 - accuracy: 0.9780 - 137ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0400 - accuracy: 0.9798 - 168ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0393 - accuracy: 0.9795 - 136ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0402 - accuracy: 0.9783 - 145ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0375 - accuracy: 0.9813 - 177ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0385 - accuracy: 0.9807 - 162ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0368 - accuracy: 0.9828 - 147ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0428 - accuracy: 0.9816 - 186ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.2919 - accuracy: 0.9208 - 650ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0592 - accuracy: 0.9712 - 164ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0453 - accuracy: 0.9792 - 179ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0411 - accuracy: 0.9786 - 167ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0390 - accuracy: 0.9813 - 162ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0376 - accuracy: 0.9834 - 169ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0361 - accuracy: 0.9825 - 168ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0371 - accuracy: 0.9837 - 178ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0351 - accuracy: 0.9843 - 161ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0348 - accuracy: 0.9837 - 152ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0477 - accuracy: 0.9774 - 182ms/epoch - 3ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.3027 - accuracy: 0.9083 - 627ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0678 - accuracy: 0.9694 - 139ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0521 - accuracy: 0.9774 - 139ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0488 - accuracy: 0.9774 - 139ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0474 - accuracy: 0.9763 - 155ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0454 - accuracy: 0.9777 - 177ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0450 - accuracy: 0.9783 - 184ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0424 - accuracy: 0.9801 - 228ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0425 - accuracy: 0.9786 - 266ms/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0424 - accuracy: 0.9774 - 217ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0314 - accuracy: 0.9822 - 218ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.3826 - accuracy: 0.8564 - 692ms/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0740 - accuracy: 0.9703 - 176ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0463 - accuracy: 0.9763 - 168ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0423 - accuracy: 0.9769 - 171ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0417 - accuracy: 0.9780 - 169ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0390 - accuracy: 0.9804 - 164ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0379 - accuracy: 0.9810 - 174ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0365 - accuracy: 0.9840 - 165ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0364 - accuracy: 0.9816 - 169ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0354 - accuracy: 0.9852 - 166ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0410 - accuracy: 0.9834 - 193ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.4422 - accuracy: 0.8398 - 652ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0721 - accuracy: 0.9700 - 143ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0476 - accuracy: 0.9783 - 143ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0431 - accuracy: 0.9789 - 147ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0425 - accuracy: 0.9792 - 142ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0410 - accuracy: 0.9789 - 142ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0407 - accuracy: 0.9807 - 142ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0368 - accuracy: 0.9834 - 145ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0369 - accuracy: 0.9834 - 170ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0350 - accuracy: 0.9837 - 188ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0493 - accuracy: 0.9751 - 226ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.2662 - accuracy: 0.9045 - 877ms/epoch - 8ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0575 - accuracy: 0.9748 - 181ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0505 - accuracy: 0.9774 - 163ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0460 - accuracy: 0.9792 - 150ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0455 - accuracy: 0.9792 - 149ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0404 - accuracy: 0.9828 - 174ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0385 - accuracy: 0.9855 - 151ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0374 - accuracy: 0.9834 - 153ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0330 - accuracy: 0.9864 - 146ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0347 - accuracy: 0.9893 - 175ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0306 - accuracy: 0.9846 - 185ms/epoch - 3ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.2325 - accuracy: 0.9261 - 684ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0528 - accuracy: 0.9763 - 173ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0420 - accuracy: 0.9798 - 178ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0402 - accuracy: 0.9798 - 178ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0384 - accuracy: 0.9804 - 175ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0367 - accuracy: 0.9804 - 177ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0353 - accuracy: 0.9804 - 225ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0351 - accuracy: 0.9807 - 370ms/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0347 - accuracy: 0.9825 - 315ms/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0323 - accuracy: 0.9843 - 289ms/epoch - 3ms/step\n",
      "53/53 - 0s - loss: 0.0450 - accuracy: 0.9822 - 294ms/epoch - 6ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.2214 - accuracy: 0.9276 - 679ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.0446 - accuracy: 0.9819 - 178ms/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.0410 - accuracy: 0.9828 - 172ms/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0397 - accuracy: 0.9840 - 184ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0371 - accuracy: 0.9831 - 228ms/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0351 - accuracy: 0.9837 - 188ms/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0328 - accuracy: 0.9861 - 164ms/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0381 - accuracy: 0.9822 - 169ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0329 - accuracy: 0.9846 - 162ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0307 - accuracy: 0.9875 - 180ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0617 - accuracy: 0.9763 - 188ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.5927 - accuracy: 0.8736 - 577ms/epoch - 5ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.3586 - accuracy: 0.8923 - 120ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.2084 - accuracy: 0.9291 - 123ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.1228 - accuracy: 0.9608 - 113ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0877 - accuracy: 0.9617 - 128ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0739 - accuracy: 0.9650 - 116ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0676 - accuracy: 0.9671 - 125ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0642 - accuracy: 0.9677 - 114ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0613 - accuracy: 0.9685 - 135ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0590 - accuracy: 0.9703 - 132ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0462 - accuracy: 0.9798 - 184ms/epoch - 3ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.5593 - accuracy: 0.8585 - 543ms/epoch - 5ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.3128 - accuracy: 0.8968 - 112ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.1661 - accuracy: 0.9422 - 118ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.0956 - accuracy: 0.9683 - 127ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0691 - accuracy: 0.9709 - 143ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0570 - accuracy: 0.9763 - 145ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0508 - accuracy: 0.9786 - 146ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0479 - accuracy: 0.9778 - 116ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0452 - accuracy: 0.9783 - 117ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0439 - accuracy: 0.9795 - 141ms/epoch - 1ms/step\n",
      "53/53 - 0s - loss: 0.0477 - accuracy: 0.9763 - 201ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "106/106 - 1s - loss: 0.5658 - accuracy: 0.8638 - 600ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "106/106 - 0s - loss: 0.3846 - accuracy: 0.8932 - 122ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "106/106 - 0s - loss: 0.2225 - accuracy: 0.9264 - 123ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "106/106 - 0s - loss: 0.1250 - accuracy: 0.9662 - 121ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "106/106 - 0s - loss: 0.0848 - accuracy: 0.9686 - 118ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "106/106 - 0s - loss: 0.0671 - accuracy: 0.9691 - 117ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "106/106 - 0s - loss: 0.0585 - accuracy: 0.9748 - 121ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "106/106 - 0s - loss: 0.0544 - accuracy: 0.9742 - 118ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "106/106 - 0s - loss: 0.0503 - accuracy: 0.9772 - 117ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "106/106 - 0s - loss: 0.0485 - accuracy: 0.9789 - 177ms/epoch - 2ms/step\n",
      "53/53 - 0s - loss: 0.0586 - accuracy: 0.9638 - 208ms/epoch - 4ms/step\n",
      "Epoch 1/10\n",
      "158/158 - 1s - loss: 0.1670 - accuracy: 0.9486 - 707ms/epoch - 4ms/step\n",
      "Epoch 2/10\n",
      "158/158 - 0s - loss: 0.0465 - accuracy: 0.9778 - 218ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "158/158 - 0s - loss: 0.0437 - accuracy: 0.9782 - 209ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "158/158 - 0s - loss: 0.0425 - accuracy: 0.9806 - 291ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "158/158 - 0s - loss: 0.0407 - accuracy: 0.9794 - 196ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "158/158 - 0s - loss: 0.0403 - accuracy: 0.9792 - 225ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "158/158 - 0s - loss: 0.0400 - accuracy: 0.9814 - 221ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "158/158 - 0s - loss: 0.0383 - accuracy: 0.9818 - 258ms/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "158/158 - 0s - loss: 0.0366 - accuracy: 0.9824 - 265ms/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "158/158 - 0s - loss: 0.0377 - accuracy: 0.9822 - 249ms/epoch - 2ms/step\n",
      "Best: 0.982199 using {'num_neurons': 64, 'num_layers': 2}\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "\n",
    "# Define the neural network model\n",
    "def create_model(num_layers=1, num_neurons=10):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_neurons, input_dim=X_train.shape[1], activation='relu'))\n",
    "    for i in range(num_layers):\n",
    "        model.add(Dense(num_neurons, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create a KerasClassifier with fixed batch_size and epochs\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=32, epochs=10, verbose=2)\n",
    "\n",
    "# Define the hyperparameter distribution to search\n",
    "param_dist = {\n",
    "    'num_layers': [1,2,3],\n",
    "    'num_neurons': [8,16,32,64],\n",
    "}\n",
    "\n",
    "# Perform randomized search\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, cv=3, n_iter=10)\n",
    "random_search_result = random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the results\n",
    "print(\"Best: %f using %s\" % (random_search_result.best_score_, random_search_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ce793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best: 0.982199 using {'num_neurons': 64, 'num_layers': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3347528d",
   "metadata": {},
   "source": [
    "## Training the best architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "abaf5987",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "158/158 - 1s - loss: 0.1778 - accuracy: 0.9434 - 638ms/epoch - 4ms/step\n",
      "Epoch 2/50\n",
      "158/158 - 0s - loss: 0.0468 - accuracy: 0.9775 - 201ms/epoch - 1ms/step\n",
      "Epoch 3/50\n",
      "158/158 - 0s - loss: 0.0425 - accuracy: 0.9794 - 225ms/epoch - 1ms/step\n",
      "Epoch 4/50\n",
      "158/158 - 0s - loss: 0.0405 - accuracy: 0.9794 - 201ms/epoch - 1ms/step\n",
      "Epoch 5/50\n",
      "158/158 - 0s - loss: 0.0389 - accuracy: 0.9810 - 204ms/epoch - 1ms/step\n",
      "Epoch 6/50\n",
      "158/158 - 0s - loss: 0.0381 - accuracy: 0.9828 - 202ms/epoch - 1ms/step\n",
      "Epoch 7/50\n",
      "158/158 - 0s - loss: 0.0372 - accuracy: 0.9824 - 202ms/epoch - 1ms/step\n",
      "Epoch 8/50\n",
      "158/158 - 0s - loss: 0.0349 - accuracy: 0.9838 - 211ms/epoch - 1ms/step\n",
      "Epoch 9/50\n",
      "158/158 - 0s - loss: 0.0330 - accuracy: 0.9856 - 208ms/epoch - 1ms/step\n",
      "Epoch 10/50\n",
      "158/158 - 0s - loss: 0.0308 - accuracy: 0.9860 - 203ms/epoch - 1ms/step\n",
      "Epoch 11/50\n",
      "158/158 - 0s - loss: 0.0286 - accuracy: 0.9875 - 202ms/epoch - 1ms/step\n",
      "Epoch 12/50\n",
      "158/158 - 0s - loss: 0.0239 - accuracy: 0.9923 - 204ms/epoch - 1ms/step\n",
      "Epoch 13/50\n",
      "158/158 - 0s - loss: 0.0205 - accuracy: 0.9935 - 206ms/epoch - 1ms/step\n",
      "Epoch 14/50\n",
      "158/158 - 0s - loss: 0.0162 - accuracy: 0.9956 - 218ms/epoch - 1ms/step\n",
      "Epoch 15/50\n",
      "158/158 - 0s - loss: 0.0157 - accuracy: 0.9966 - 220ms/epoch - 1ms/step\n",
      "Epoch 16/50\n",
      "158/158 - 0s - loss: 0.0136 - accuracy: 0.9966 - 216ms/epoch - 1ms/step\n",
      "Epoch 17/50\n",
      "158/158 - 0s - loss: 0.0120 - accuracy: 0.9976 - 230ms/epoch - 1ms/step\n",
      "Epoch 18/50\n",
      "158/158 - 0s - loss: 0.0110 - accuracy: 0.9972 - 234ms/epoch - 1ms/step\n",
      "Epoch 19/50\n",
      "158/158 - 0s - loss: 0.0099 - accuracy: 0.9976 - 234ms/epoch - 1ms/step\n",
      "Epoch 20/50\n",
      "158/158 - 0s - loss: 0.0093 - accuracy: 0.9974 - 235ms/epoch - 1ms/step\n",
      "Epoch 21/50\n",
      "158/158 - 0s - loss: 0.0109 - accuracy: 0.9966 - 205ms/epoch - 1ms/step\n",
      "Epoch 22/50\n",
      "158/158 - 0s - loss: 0.0078 - accuracy: 0.9970 - 243ms/epoch - 2ms/step\n",
      "Epoch 23/50\n",
      "158/158 - 0s - loss: 0.0056 - accuracy: 0.9982 - 232ms/epoch - 1ms/step\n",
      "Epoch 24/50\n",
      "158/158 - 0s - loss: 0.0039 - accuracy: 0.9984 - 229ms/epoch - 1ms/step\n",
      "Epoch 25/50\n",
      "158/158 - 0s - loss: 0.0043 - accuracy: 0.9986 - 203ms/epoch - 1ms/step\n",
      "Epoch 26/50\n",
      "158/158 - 0s - loss: 0.0029 - accuracy: 0.9996 - 233ms/epoch - 1ms/step\n",
      "Epoch 27/50\n",
      "158/158 - 0s - loss: 0.0045 - accuracy: 0.9980 - 202ms/epoch - 1ms/step\n",
      "Epoch 28/50\n",
      "158/158 - 0s - loss: 0.0023 - accuracy: 0.9992 - 256ms/epoch - 2ms/step\n",
      "Epoch 29/50\n",
      "158/158 - 0s - loss: 0.0023 - accuracy: 0.9994 - 263ms/epoch - 2ms/step\n",
      "Epoch 30/50\n",
      "158/158 - 0s - loss: 0.0014 - accuracy: 0.9996 - 246ms/epoch - 2ms/step\n",
      "Epoch 31/50\n",
      "158/158 - 0s - loss: 0.0039 - accuracy: 0.9988 - 229ms/epoch - 1ms/step\n",
      "Epoch 32/50\n",
      "158/158 - 0s - loss: 0.0024 - accuracy: 0.9992 - 226ms/epoch - 1ms/step\n",
      "Epoch 33/50\n",
      "158/158 - 0s - loss: 0.0023 - accuracy: 0.9992 - 221ms/epoch - 1ms/step\n",
      "Epoch 34/50\n",
      "158/158 - 0s - loss: 0.0039 - accuracy: 0.9990 - 207ms/epoch - 1ms/step\n",
      "Epoch 35/50\n",
      "158/158 - 0s - loss: 0.0011 - accuracy: 0.9996 - 238ms/epoch - 2ms/step\n",
      "Epoch 36/50\n",
      "158/158 - 0s - loss: 0.0037 - accuracy: 0.9990 - 199ms/epoch - 1ms/step\n",
      "Epoch 37/50\n",
      "158/158 - 0s - loss: 0.0058 - accuracy: 0.9988 - 232ms/epoch - 1ms/step\n",
      "Epoch 38/50\n",
      "158/158 - 0s - loss: 0.0010 - accuracy: 0.9996 - 232ms/epoch - 1ms/step\n",
      "Epoch 39/50\n",
      "158/158 - 0s - loss: 9.6969e-04 - accuracy: 0.9996 - 233ms/epoch - 1ms/step\n",
      "Epoch 40/50\n",
      "158/158 - 0s - loss: 0.0029 - accuracy: 0.9990 - 214ms/epoch - 1ms/step\n",
      "Epoch 41/50\n",
      "158/158 - 0s - loss: 0.0012 - accuracy: 0.9996 - 207ms/epoch - 1ms/step\n",
      "Epoch 42/50\n",
      "158/158 - 0s - loss: 8.5491e-04 - accuracy: 0.9998 - 217ms/epoch - 1ms/step\n",
      "Epoch 43/50\n",
      "158/158 - 0s - loss: 7.0465e-04 - accuracy: 0.9996 - 233ms/epoch - 1ms/step\n",
      "Epoch 44/50\n",
      "158/158 - 0s - loss: 0.0019 - accuracy: 0.9992 - 260ms/epoch - 2ms/step\n",
      "Epoch 45/50\n",
      "158/158 - 0s - loss: 0.0015 - accuracy: 0.9994 - 264ms/epoch - 2ms/step\n",
      "Epoch 46/50\n",
      "158/158 - 0s - loss: 0.0018 - accuracy: 0.9996 - 250ms/epoch - 2ms/step\n",
      "Epoch 47/50\n",
      "158/158 - 0s - loss: 0.0019 - accuracy: 0.9990 - 239ms/epoch - 2ms/step\n",
      "Epoch 48/50\n",
      "158/158 - 0s - loss: 0.0044 - accuracy: 0.9982 - 257ms/epoch - 2ms/step\n",
      "Epoch 49/50\n",
      "158/158 - 0s - loss: 7.3504e-04 - accuracy: 0.9998 - 243ms/epoch - 2ms/step\n",
      "Epoch 50/50\n",
      "158/158 - 0s - loss: 0.0015 - accuracy: 0.9994 - 260ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8665817d90>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "best_num_layers = random_search_result.best_params_[\"num_layers\"]\n",
    "best_num_neurons = random_search_result.best_params_[\"num_neurons\"]\n",
    "model = create_model(num_layers=best_num_layers, num_neurons=best_num_neurons)\n",
    "model.fit(X_train, y_train, epochs=50, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ef1b46e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 2ms/step\n",
      "[[1129    2]\n",
      " [   3  131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1131\n",
      "           1       0.98      0.98      0.98       134\n",
      "\n",
      "    accuracy                           1.00      1265\n",
      "   macro avg       0.99      0.99      0.99      1265\n",
      "weighted avg       1.00      1.00      1.00      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use the trained classifier to predict the class labels for the test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.round(y_pred)\n",
    "# Evaluate the classifier's performance on the test data\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bda3518",
   "metadata": {},
   "source": [
    "Neural network performs slightly better than non-linear SVM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "18aa9797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9960\n",
      "Accuracy: 0.9960\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the testing set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "\n",
    "# Print the accuracy without rounding\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebe7570",
   "metadata": {},
   "source": [
    "# Structure Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a8827c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['Bidder_Tendency', 'Successive_Outbidding', 'Last_Bidding',\n",
      "       'Winning_Ratio'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Standardize the features using the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Fit a Lasso regression model on the training data\n",
    "alpha = 0.006  # regularization strength\n",
    "lasso = Lasso(alpha=alpha)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Select the features with non-zero coefficients\n",
    "selected_features = X.columns[lasso.coef_ != 0]\n",
    "\n",
    "# Print the selected features\n",
    "print(\"Selected features:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "71ff67a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['Bidder_Tendency', 'Bidding_Ratio', 'Successive_Outbidding', 'Winning_Ratio']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "\n",
    "# Get the feature matrix X and target vector y\n",
    "X_train_ = data.drop(['Bidder_ID', 'Class'], axis=1)\n",
    "y_train_ = data['Class']\n",
    "\n",
    "k = 4\n",
    "knn = KNeighborsClassifier(n_neighbors=k) \n",
    "selector = SelectKBest(score_func=f_classif, k=k)\n",
    "# selector = SelectKBest(score_func=chi2, k=k)\n",
    "X_train_new = selector.fit_transform(X_train_, y_train_)\n",
    "\n",
    "\n",
    "# Print the selected feature names\n",
    "selected_features = X_train_.columns[selector.get_support()]\n",
    "print(\"Selected features:\", list(selected_features))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321b6b20",
   "metadata": {},
   "source": [
    "Training the model with the selected features to find which feature selection is a better technique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f1f789e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = data[['Bidder_Tendency', 'Successive_Outbidding', 'Last_Bidding',\n",
    "       'Winning_Ratio']]\n",
    "y = data['Class']\n",
    "X_train_sl_ft_1, X_test_sl_ft_1, y_train_sl_ft_1, y_test_sl_ft_1 = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e44c32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b2174140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "def create_model_(num_layers=1, num_neurons=10):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_neurons, input_dim=X_train_.shape[1], activation='relu'))\n",
    "    for i in range(num_layers):\n",
    "        model.add(Dense(num_neurons, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8d25aaa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "158/158 - 1s - loss: 0.2030 - accuracy: 0.9389 - 646ms/epoch - 4ms/step\n",
      "Epoch 2/50\n",
      "158/158 - 0s - loss: 0.0479 - accuracy: 0.9777 - 202ms/epoch - 1ms/step\n",
      "Epoch 3/50\n",
      "158/158 - 0s - loss: 0.0476 - accuracy: 0.9775 - 205ms/epoch - 1ms/step\n",
      "Epoch 4/50\n",
      "158/158 - 0s - loss: 0.0455 - accuracy: 0.9784 - 204ms/epoch - 1ms/step\n",
      "Epoch 5/50\n",
      "158/158 - 0s - loss: 0.0449 - accuracy: 0.9778 - 209ms/epoch - 1ms/step\n",
      "Epoch 6/50\n",
      "158/158 - 0s - loss: 0.0448 - accuracy: 0.9798 - 237ms/epoch - 1ms/step\n",
      "Epoch 7/50\n",
      "158/158 - 0s - loss: 0.0444 - accuracy: 0.9788 - 211ms/epoch - 1ms/step\n",
      "Epoch 8/50\n",
      "158/158 - 0s - loss: 0.0437 - accuracy: 0.9794 - 206ms/epoch - 1ms/step\n",
      "Epoch 9/50\n",
      "158/158 - 0s - loss: 0.0416 - accuracy: 0.9800 - 206ms/epoch - 1ms/step\n",
      "Epoch 10/50\n",
      "158/158 - 0s - loss: 0.0441 - accuracy: 0.9784 - 202ms/epoch - 1ms/step\n",
      "Epoch 11/50\n",
      "158/158 - 0s - loss: 0.0421 - accuracy: 0.9796 - 204ms/epoch - 1ms/step\n",
      "Epoch 12/50\n",
      "158/158 - 0s - loss: 0.0433 - accuracy: 0.9796 - 202ms/epoch - 1ms/step\n",
      "Epoch 13/50\n",
      "158/158 - 0s - loss: 0.0420 - accuracy: 0.9802 - 210ms/epoch - 1ms/step\n",
      "Epoch 14/50\n",
      "158/158 - 0s - loss: 0.0424 - accuracy: 0.9802 - 199ms/epoch - 1ms/step\n",
      "Epoch 15/50\n",
      "158/158 - 0s - loss: 0.0426 - accuracy: 0.9804 - 200ms/epoch - 1ms/step\n",
      "Epoch 16/50\n",
      "158/158 - 0s - loss: 0.0422 - accuracy: 0.9798 - 243ms/epoch - 2ms/step\n",
      "Epoch 17/50\n",
      "158/158 - 0s - loss: 0.0415 - accuracy: 0.9800 - 279ms/epoch - 2ms/step\n",
      "Epoch 18/50\n",
      "158/158 - 0s - loss: 0.0429 - accuracy: 0.9790 - 209ms/epoch - 1ms/step\n",
      "Epoch 19/50\n",
      "158/158 - 0s - loss: 0.0421 - accuracy: 0.9798 - 198ms/epoch - 1ms/step\n",
      "Epoch 20/50\n",
      "158/158 - 0s - loss: 0.0428 - accuracy: 0.9798 - 201ms/epoch - 1ms/step\n",
      "Epoch 21/50\n",
      "158/158 - 0s - loss: 0.0428 - accuracy: 0.9792 - 202ms/epoch - 1ms/step\n",
      "Epoch 22/50\n",
      "158/158 - 0s - loss: 0.0421 - accuracy: 0.9788 - 205ms/epoch - 1ms/step\n",
      "Epoch 23/50\n",
      "158/158 - 0s - loss: 0.0411 - accuracy: 0.9802 - 201ms/epoch - 1ms/step\n",
      "Epoch 24/50\n",
      "158/158 - 0s - loss: 0.0421 - accuracy: 0.9796 - 210ms/epoch - 1ms/step\n",
      "Epoch 25/50\n",
      "158/158 - 0s - loss: 0.0416 - accuracy: 0.9792 - 199ms/epoch - 1ms/step\n",
      "Epoch 26/50\n",
      "158/158 - 0s - loss: 0.0418 - accuracy: 0.9794 - 202ms/epoch - 1ms/step\n",
      "Epoch 27/50\n",
      "158/158 - 0s - loss: 0.0416 - accuracy: 0.9798 - 201ms/epoch - 1ms/step\n",
      "Epoch 28/50\n",
      "158/158 - 0s - loss: 0.0415 - accuracy: 0.9798 - 203ms/epoch - 1ms/step\n",
      "Epoch 29/50\n",
      "158/158 - 0s - loss: 0.0410 - accuracy: 0.9802 - 206ms/epoch - 1ms/step\n",
      "Epoch 30/50\n",
      "158/158 - 0s - loss: 0.0416 - accuracy: 0.9798 - 202ms/epoch - 1ms/step\n",
      "Epoch 31/50\n",
      "158/158 - 0s - loss: 0.0422 - accuracy: 0.9786 - 246ms/epoch - 2ms/step\n",
      "Epoch 32/50\n",
      "158/158 - 0s - loss: 0.0410 - accuracy: 0.9794 - 218ms/epoch - 1ms/step\n",
      "Epoch 33/50\n",
      "158/158 - 0s - loss: 0.0408 - accuracy: 0.9798 - 202ms/epoch - 1ms/step\n",
      "Epoch 34/50\n",
      "158/158 - 0s - loss: 0.0406 - accuracy: 0.9804 - 205ms/epoch - 1ms/step\n",
      "Epoch 35/50\n",
      "158/158 - 0s - loss: 0.0406 - accuracy: 0.9786 - 219ms/epoch - 1ms/step\n",
      "Epoch 36/50\n",
      "158/158 - 0s - loss: 0.0407 - accuracy: 0.9796 - 208ms/epoch - 1ms/step\n",
      "Epoch 37/50\n",
      "158/158 - 0s - loss: 0.0400 - accuracy: 0.9812 - 224ms/epoch - 1ms/step\n",
      "Epoch 38/50\n",
      "158/158 - 0s - loss: 0.0426 - accuracy: 0.9788 - 204ms/epoch - 1ms/step\n",
      "Epoch 39/50\n",
      "158/158 - 0s - loss: 0.0406 - accuracy: 0.9804 - 202ms/epoch - 1ms/step\n",
      "Epoch 40/50\n",
      "158/158 - 0s - loss: 0.0411 - accuracy: 0.9796 - 203ms/epoch - 1ms/step\n",
      "Epoch 41/50\n",
      "158/158 - 0s - loss: 0.0404 - accuracy: 0.9804 - 221ms/epoch - 1ms/step\n",
      "Epoch 42/50\n",
      "158/158 - 0s - loss: 0.0409 - accuracy: 0.9788 - 208ms/epoch - 1ms/step\n",
      "Epoch 43/50\n",
      "158/158 - 0s - loss: 0.0404 - accuracy: 0.9818 - 208ms/epoch - 1ms/step\n",
      "Epoch 44/50\n",
      "158/158 - 0s - loss: 0.0413 - accuracy: 0.9808 - 203ms/epoch - 1ms/step\n",
      "Epoch 45/50\n",
      "158/158 - 0s - loss: 0.0404 - accuracy: 0.9804 - 228ms/epoch - 1ms/step\n",
      "Epoch 46/50\n",
      "158/158 - 0s - loss: 0.0406 - accuracy: 0.9802 - 210ms/epoch - 1ms/step\n",
      "Epoch 47/50\n",
      "158/158 - 0s - loss: 0.0402 - accuracy: 0.9792 - 206ms/epoch - 1ms/step\n",
      "Epoch 48/50\n",
      "158/158 - 0s - loss: 0.0400 - accuracy: 0.9794 - 206ms/epoch - 1ms/step\n",
      "Epoch 49/50\n",
      "158/158 - 0s - loss: 0.0404 - accuracy: 0.9796 - 202ms/epoch - 1ms/step\n",
      "Epoch 50/50\n",
      "158/158 - 0s - loss: 0.0404 - accuracy: 0.9808 - 203ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86597d80a0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model_(num_layers=2, num_neurons=64)\n",
    "model.fit(X_train_sl_ft_1, y_train_sl_ft_1, epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1cd74af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 2ms/step\n",
      "[[1115   25]\n",
      " [   0  125]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      1140\n",
      "           1       0.83      1.00      0.91       125\n",
      "\n",
      "    accuracy                           0.98      1265\n",
      "   macro avg       0.92      0.99      0.95      1265\n",
      "weighted avg       0.98      0.98      0.98      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use the trained classifier to predict the class labels for the test data\n",
    "y_pred_ = model.predict(X_test_sl_ft_1)\n",
    "y_pred_ = np.round(y_pred_sl_ft_1)\n",
    "# Evaluate the classifier's performance on the test data\n",
    "print(confusion_matrix(y_test_sl_ft_1, y_pred_sl_ft_1))\n",
    "print(classification_report(y_test_sl_ft_1, y_pred_sl_ft_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c2e6ab72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "158/158 - 1s - loss: 0.2068 - accuracy: 0.9502 - 667ms/epoch - 4ms/step\n",
      "Epoch 2/50\n",
      "158/158 - 0s - loss: 0.0466 - accuracy: 0.9790 - 222ms/epoch - 1ms/step\n",
      "Epoch 3/50\n",
      "158/158 - 0s - loss: 0.0435 - accuracy: 0.9798 - 232ms/epoch - 1ms/step\n",
      "Epoch 4/50\n",
      "158/158 - 0s - loss: 0.0420 - accuracy: 0.9804 - 326ms/epoch - 2ms/step\n",
      "Epoch 5/50\n",
      "158/158 - 0s - loss: 0.0421 - accuracy: 0.9810 - 276ms/epoch - 2ms/step\n",
      "Epoch 6/50\n",
      "158/158 - 0s - loss: 0.0407 - accuracy: 0.9814 - 286ms/epoch - 2ms/step\n",
      "Epoch 7/50\n",
      "158/158 - 0s - loss: 0.0412 - accuracy: 0.9814 - 275ms/epoch - 2ms/step\n",
      "Epoch 8/50\n",
      "158/158 - 0s - loss: 0.0408 - accuracy: 0.9800 - 250ms/epoch - 2ms/step\n",
      "Epoch 9/50\n",
      "158/158 - 0s - loss: 0.0417 - accuracy: 0.9802 - 214ms/epoch - 1ms/step\n",
      "Epoch 10/50\n",
      "158/158 - 0s - loss: 0.0390 - accuracy: 0.9822 - 207ms/epoch - 1ms/step\n",
      "Epoch 11/50\n",
      "158/158 - 0s - loss: 0.0397 - accuracy: 0.9822 - 208ms/epoch - 1ms/step\n",
      "Epoch 12/50\n",
      "158/158 - 0s - loss: 0.0406 - accuracy: 0.9802 - 229ms/epoch - 1ms/step\n",
      "Epoch 13/50\n",
      "158/158 - 0s - loss: 0.0408 - accuracy: 0.9808 - 227ms/epoch - 1ms/step\n",
      "Epoch 14/50\n",
      "158/158 - 0s - loss: 0.0396 - accuracy: 0.9828 - 233ms/epoch - 1ms/step\n",
      "Epoch 15/50\n",
      "158/158 - 0s - loss: 0.0394 - accuracy: 0.9812 - 209ms/epoch - 1ms/step\n",
      "Epoch 16/50\n",
      "158/158 - 0s - loss: 0.0384 - accuracy: 0.9830 - 213ms/epoch - 1ms/step\n",
      "Epoch 17/50\n",
      "158/158 - 0s - loss: 0.0400 - accuracy: 0.9824 - 275ms/epoch - 2ms/step\n",
      "Epoch 18/50\n",
      "158/158 - 0s - loss: 0.0395 - accuracy: 0.9810 - 296ms/epoch - 2ms/step\n",
      "Epoch 19/50\n",
      "158/158 - 0s - loss: 0.0393 - accuracy: 0.9818 - 281ms/epoch - 2ms/step\n",
      "Epoch 20/50\n",
      "158/158 - 0s - loss: 0.0386 - accuracy: 0.9820 - 237ms/epoch - 1ms/step\n",
      "Epoch 21/50\n",
      "158/158 - 0s - loss: 0.0392 - accuracy: 0.9822 - 219ms/epoch - 1ms/step\n",
      "Epoch 22/50\n",
      "158/158 - 0s - loss: 0.0403 - accuracy: 0.9822 - 240ms/epoch - 2ms/step\n",
      "Epoch 23/50\n",
      "158/158 - 0s - loss: 0.0385 - accuracy: 0.9824 - 264ms/epoch - 2ms/step\n",
      "Epoch 24/50\n",
      "158/158 - 0s - loss: 0.0400 - accuracy: 0.9826 - 205ms/epoch - 1ms/step\n",
      "Epoch 25/50\n",
      "158/158 - 0s - loss: 0.0404 - accuracy: 0.9812 - 206ms/epoch - 1ms/step\n",
      "Epoch 26/50\n",
      "158/158 - 0s - loss: 0.0402 - accuracy: 0.9802 - 219ms/epoch - 1ms/step\n",
      "Epoch 27/50\n",
      "158/158 - 0s - loss: 0.0390 - accuracy: 0.9824 - 208ms/epoch - 1ms/step\n",
      "Epoch 28/50\n",
      "158/158 - 0s - loss: 0.0390 - accuracy: 0.9816 - 248ms/epoch - 2ms/step\n",
      "Epoch 29/50\n",
      "158/158 - 0s - loss: 0.0385 - accuracy: 0.9820 - 248ms/epoch - 2ms/step\n",
      "Epoch 30/50\n",
      "158/158 - 0s - loss: 0.0389 - accuracy: 0.9828 - 248ms/epoch - 2ms/step\n",
      "Epoch 31/50\n",
      "158/158 - 0s - loss: 0.0381 - accuracy: 0.9824 - 217ms/epoch - 1ms/step\n",
      "Epoch 32/50\n",
      "158/158 - 0s - loss: 0.0390 - accuracy: 0.9824 - 219ms/epoch - 1ms/step\n",
      "Epoch 33/50\n",
      "158/158 - 0s - loss: 0.0388 - accuracy: 0.9808 - 203ms/epoch - 1ms/step\n",
      "Epoch 34/50\n",
      "158/158 - 0s - loss: 0.0384 - accuracy: 0.9822 - 205ms/epoch - 1ms/step\n",
      "Epoch 35/50\n",
      "158/158 - 0s - loss: 0.0377 - accuracy: 0.9820 - 202ms/epoch - 1ms/step\n",
      "Epoch 36/50\n",
      "158/158 - 0s - loss: 0.0394 - accuracy: 0.9810 - 236ms/epoch - 1ms/step\n",
      "Epoch 37/50\n",
      "158/158 - 0s - loss: 0.0387 - accuracy: 0.9822 - 239ms/epoch - 2ms/step\n",
      "Epoch 38/50\n",
      "158/158 - 0s - loss: 0.0385 - accuracy: 0.9830 - 251ms/epoch - 2ms/step\n",
      "Epoch 39/50\n",
      "158/158 - 0s - loss: 0.0383 - accuracy: 0.9824 - 213ms/epoch - 1ms/step\n",
      "Epoch 40/50\n",
      "158/158 - 0s - loss: 0.0382 - accuracy: 0.9826 - 214ms/epoch - 1ms/step\n",
      "Epoch 41/50\n",
      "158/158 - 0s - loss: 0.0383 - accuracy: 0.9826 - 203ms/epoch - 1ms/step\n",
      "Epoch 42/50\n",
      "158/158 - 0s - loss: 0.0383 - accuracy: 0.9812 - 207ms/epoch - 1ms/step\n",
      "Epoch 43/50\n",
      "158/158 - 0s - loss: 0.0387 - accuracy: 0.9822 - 203ms/epoch - 1ms/step\n",
      "Epoch 44/50\n",
      "158/158 - 0s - loss: 0.0379 - accuracy: 0.9826 - 206ms/epoch - 1ms/step\n",
      "Epoch 45/50\n",
      "158/158 - 0s - loss: 0.0387 - accuracy: 0.9822 - 241ms/epoch - 2ms/step\n",
      "Epoch 46/50\n",
      "158/158 - 0s - loss: 0.0384 - accuracy: 0.9822 - 254ms/epoch - 2ms/step\n",
      "Epoch 47/50\n",
      "158/158 - 0s - loss: 0.0383 - accuracy: 0.9828 - 256ms/epoch - 2ms/step\n",
      "Epoch 48/50\n",
      "158/158 - 0s - loss: 0.0385 - accuracy: 0.9822 - 232ms/epoch - 1ms/step\n",
      "Epoch 49/50\n",
      "158/158 - 0s - loss: 0.0384 - accuracy: 0.9822 - 229ms/epoch - 1ms/step\n",
      "Epoch 50/50\n",
      "158/158 - 0s - loss: 0.0386 - accuracy: 0.9820 - 201ms/epoch - 1ms/step\n",
      "40/40 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_sl_ft_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[137], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Use the trained classifier to predict the class labels for the test data\u001b[39;00m\n\u001b[1;32m      9\u001b[0m y_pred_ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_sl_ft_2)\n\u001b[0;32m---> 10\u001b[0m y_pred_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(\u001b[43my_pred_sl_ft_2\u001b[49m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Evaluate the classifier's performance on the test data\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(confusion_matrix(y_test_sl_ft_2, y_pred_sl_ft_2))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred_sl_ft_2' is not defined"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = data[['Bidder_Tendency', 'Bidding_Ratio', 'Successive_Outbidding', 'Winning_Ratio']]\n",
    "y = data['Class']\n",
    "X_train_sl_ft_2, X_test_sl_ft_2, y_train_sl_ft_2, y_test_sl_ft_2 = train_test_split(X, y, test_size=0.2)\n",
    "model = create_model_(num_layers=2, num_neurons=64)\n",
    "model.fit(X_train_sl_ft_2, y_train_sl_ft_2, epochs=50, verbose=2)\n",
    "\n",
    "# Use the trained classifier to predict the class labels for the test data\n",
    "y_pred_ = model.predict(X_test_sl_ft_2)\n",
    "y_pred_ = np.round(y_pred_sl_ft_2)\n",
    "# Evaluate the classifier's performance on the test data\n",
    "print(confusion_matrix(y_test_sl_ft_2, y_pred_sl_ft_2))\n",
    "print(classification_report(y_test_sl_ft_2, y_pred_sl_ft_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3b612a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 2ms/step\n",
      "[[1102   25]\n",
      " [   0  138]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      1127\n",
      "           1       0.85      1.00      0.92       138\n",
      "\n",
      "    accuracy                           0.98      1265\n",
      "   macro avg       0.92      0.99      0.95      1265\n",
      "weighted avg       0.98      0.98      0.98      1265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the trained classifier to predict the class labels for the test data\n",
    "y_pred_sl_ft_2 = model.predict(X_test_sl_ft_2)\n",
    "y_pred_sl_ft_2 = np.round(y_pred_sl_ft_2)\n",
    "# Evaluate the classifier's performance on the test data\n",
    "print(confusion_matrix(y_test_sl_ft_2, y_pred_sl_ft_2))\n",
    "print(classification_report(y_test_sl_ft_2, y_pred_sl_ft_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9a7d70",
   "metadata": {},
   "source": [
    "Both feature selections provide similar accuracies. \n",
    "But we are going to conisder Lasso feature selection method for our case, because Lasso is linear and uses L1 regularization to shrink coefficients of the features towards zero which can also prevent the problem of overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35926184",
   "metadata": {},
   "source": [
    "## Using the best model from part 2 and part 3 on the selected features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f8fd960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Selected features : ['Bidder_Tendency', 'Successive_Outbidding', 'Last_Bidding', 'Winning_Ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0f332047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = data[['Bidder_Tendency', 'Successive_Outbidding', 'Last_Bidding',\n",
    "       'Winning_Ratio']]\n",
    "y = data['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "de0ef5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9762845849802372\n"
     ]
    }
   ],
   "source": [
    "# BEST MODEL FROM PART - 2 (Random Forest)\n",
    "# Best hyperparameters:  \n",
    "# {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
    "\n",
    "# Define the random forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=20)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(acc_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7151dd7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "158/158 - 1s - loss: 0.1913 - accuracy: 0.9409 - 766ms/epoch - 5ms/step\n",
      "Epoch 2/50\n",
      "158/158 - 0s - loss: 0.0458 - accuracy: 0.9794 - 231ms/epoch - 1ms/step\n",
      "Epoch 3/50\n",
      "158/158 - 0s - loss: 0.0430 - accuracy: 0.9816 - 340ms/epoch - 2ms/step\n",
      "Epoch 4/50\n",
      "158/158 - 0s - loss: 0.0425 - accuracy: 0.9814 - 279ms/epoch - 2ms/step\n",
      "Epoch 5/50\n",
      "158/158 - 0s - loss: 0.0409 - accuracy: 0.9812 - 259ms/epoch - 2ms/step\n",
      "Epoch 6/50\n",
      "158/158 - 0s - loss: 0.0409 - accuracy: 0.9814 - 236ms/epoch - 1ms/step\n",
      "Epoch 7/50\n",
      "158/158 - 0s - loss: 0.0430 - accuracy: 0.9808 - 210ms/epoch - 1ms/step\n",
      "Epoch 8/50\n",
      "158/158 - 0s - loss: 0.0410 - accuracy: 0.9808 - 223ms/epoch - 1ms/step\n",
      "Epoch 9/50\n",
      "158/158 - 0s - loss: 0.0408 - accuracy: 0.9808 - 244ms/epoch - 2ms/step\n",
      "Epoch 10/50\n",
      "158/158 - 0s - loss: 0.0409 - accuracy: 0.9816 - 283ms/epoch - 2ms/step\n",
      "Epoch 11/50\n",
      "158/158 - 0s - loss: 0.0403 - accuracy: 0.9814 - 294ms/epoch - 2ms/step\n",
      "Epoch 12/50\n",
      "158/158 - 0s - loss: 0.0410 - accuracy: 0.9800 - 227ms/epoch - 1ms/step\n",
      "Epoch 13/50\n",
      "158/158 - 0s - loss: 0.0425 - accuracy: 0.9818 - 223ms/epoch - 1ms/step\n",
      "Epoch 14/50\n",
      "158/158 - 0s - loss: 0.0391 - accuracy: 0.9826 - 240ms/epoch - 2ms/step\n",
      "Epoch 15/50\n",
      "158/158 - 0s - loss: 0.0408 - accuracy: 0.9802 - 210ms/epoch - 1ms/step\n",
      "Epoch 16/50\n",
      "158/158 - 0s - loss: 0.0393 - accuracy: 0.9822 - 215ms/epoch - 1ms/step\n",
      "Epoch 17/50\n",
      "158/158 - 0s - loss: 0.0395 - accuracy: 0.9818 - 239ms/epoch - 2ms/step\n",
      "Epoch 18/50\n",
      "158/158 - 0s - loss: 0.0392 - accuracy: 0.9816 - 231ms/epoch - 1ms/step\n",
      "Epoch 19/50\n",
      "158/158 - 0s - loss: 0.0399 - accuracy: 0.9816 - 218ms/epoch - 1ms/step\n",
      "Epoch 20/50\n",
      "158/158 - 0s - loss: 0.0391 - accuracy: 0.9816 - 210ms/epoch - 1ms/step\n",
      "Epoch 21/50\n",
      "158/158 - 0s - loss: 0.0385 - accuracy: 0.9824 - 209ms/epoch - 1ms/step\n",
      "Epoch 22/50\n",
      "158/158 - 0s - loss: 0.0391 - accuracy: 0.9820 - 247ms/epoch - 2ms/step\n",
      "Epoch 23/50\n",
      "158/158 - 0s - loss: 0.0392 - accuracy: 0.9814 - 273ms/epoch - 2ms/step\n",
      "Epoch 24/50\n",
      "158/158 - 0s - loss: 0.0393 - accuracy: 0.9812 - 213ms/epoch - 1ms/step\n",
      "Epoch 25/50\n",
      "158/158 - 0s - loss: 0.0390 - accuracy: 0.9824 - 209ms/epoch - 1ms/step\n",
      "Epoch 26/50\n",
      "158/158 - 0s - loss: 0.0384 - accuracy: 0.9828 - 207ms/epoch - 1ms/step\n",
      "Epoch 27/50\n",
      "158/158 - 0s - loss: 0.0386 - accuracy: 0.9814 - 206ms/epoch - 1ms/step\n",
      "Epoch 28/50\n",
      "158/158 - 0s - loss: 0.0384 - accuracy: 0.9818 - 211ms/epoch - 1ms/step\n",
      "Epoch 29/50\n",
      "158/158 - 0s - loss: 0.0398 - accuracy: 0.9816 - 208ms/epoch - 1ms/step\n",
      "Epoch 30/50\n",
      "158/158 - 0s - loss: 0.0392 - accuracy: 0.9812 - 208ms/epoch - 1ms/step\n",
      "Epoch 31/50\n",
      "158/158 - 0s - loss: 0.0391 - accuracy: 0.9822 - 221ms/epoch - 1ms/step\n",
      "Epoch 32/50\n",
      "158/158 - 0s - loss: 0.0385 - accuracy: 0.9822 - 218ms/epoch - 1ms/step\n",
      "Epoch 33/50\n",
      "158/158 - 0s - loss: 0.0391 - accuracy: 0.9812 - 214ms/epoch - 1ms/step\n",
      "Epoch 34/50\n",
      "158/158 - 0s - loss: 0.0382 - accuracy: 0.9822 - 296ms/epoch - 2ms/step\n",
      "Epoch 35/50\n",
      "158/158 - 0s - loss: 0.0392 - accuracy: 0.9826 - 465ms/epoch - 3ms/step\n",
      "Epoch 36/50\n",
      "158/158 - 0s - loss: 0.0386 - accuracy: 0.9820 - 271ms/epoch - 2ms/step\n",
      "Epoch 37/50\n",
      "158/158 - 0s - loss: 0.0378 - accuracy: 0.9814 - 234ms/epoch - 1ms/step\n",
      "Epoch 38/50\n",
      "158/158 - 0s - loss: 0.0378 - accuracy: 0.9822 - 296ms/epoch - 2ms/step\n",
      "Epoch 39/50\n",
      "158/158 - 0s - loss: 0.0387 - accuracy: 0.9818 - 301ms/epoch - 2ms/step\n",
      "Epoch 40/50\n",
      "158/158 - 0s - loss: 0.0384 - accuracy: 0.9824 - 265ms/epoch - 2ms/step\n",
      "Epoch 41/50\n",
      "158/158 - 0s - loss: 0.0375 - accuracy: 0.9824 - 225ms/epoch - 1ms/step\n",
      "Epoch 42/50\n",
      "158/158 - 0s - loss: 0.0383 - accuracy: 0.9822 - 225ms/epoch - 1ms/step\n",
      "Epoch 43/50\n",
      "158/158 - 0s - loss: 0.0380 - accuracy: 0.9820 - 220ms/epoch - 1ms/step\n",
      "Epoch 44/50\n",
      "158/158 - 0s - loss: 0.0380 - accuracy: 0.9812 - 217ms/epoch - 1ms/step\n",
      "Epoch 45/50\n",
      "158/158 - 0s - loss: 0.0386 - accuracy: 0.9826 - 218ms/epoch - 1ms/step\n",
      "Epoch 46/50\n",
      "158/158 - 0s - loss: 0.0386 - accuracy: 0.9828 - 240ms/epoch - 2ms/step\n",
      "Epoch 47/50\n",
      "158/158 - 0s - loss: 0.0380 - accuracy: 0.9824 - 215ms/epoch - 1ms/step\n",
      "Epoch 48/50\n",
      "158/158 - 0s - loss: 0.0375 - accuracy: 0.9830 - 226ms/epoch - 1ms/step\n",
      "Epoch 49/50\n",
      "158/158 - 0s - loss: 0.0381 - accuracy: 0.9824 - 289ms/epoch - 2ms/step\n",
      "Epoch 50/50\n",
      "158/158 - 0s - loss: 0.0378 - accuracy: 0.9824 - 320ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8659c2e9a0>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the neural network model\n",
    "def create_model_(num_layers=1, num_neurons=10):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_neurons, input_dim=X_train_.shape[1], activation='relu'))\n",
    "    for i in range(num_layers):\n",
    "        model.add(Dense(num_neurons, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model_(num_layers=2, num_neurons=64)\n",
    "model.fit(X_train, y_train, epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e4ece8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9810\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the testing set\n",
    "loss, accuracy_nn = model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "21d5986a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best part 2 model (Rf) on selected features : 0.9763\n",
      "Accuracy of the best part 3 model (NN) on selected features: 0.9810\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy without rounding\n",
    "print(\"Accuracy of the best part 2 model (Rf) on selected features : {:.4f}\".format(acc_rf))\n",
    "print(\"Accuracy of the best part 3 model (NN) on selected features: {:.4f}\".format(accuracy_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "bacb2c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features (RF): Index(['Successive_Outbidding', 'Last_Bidding', 'Winning_Ratio',\n",
      "       'Auction_Duration'],\n",
      "      dtype='object')\n",
      "Best score (RF): 0.9980229335022266\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=20, min_samples_split=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=20, min_samples_split=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=20, min_samples_split=5)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100)\n",
    "\n",
    "sfs = SFS(rf,\n",
    "          k_features=(1, X.shape[1]),\n",
    "          forward=True,\n",
    "          floating=True,\n",
    "          scoring='accuracy',\n",
    "          cv=5,\n",
    "          n_jobs=-1)\n",
    "\n",
    "sfs = sfs.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Get the selected column names\n",
    "selected_columns = X.columns[list(sfs.k_feature_idx_)]\n",
    "\n",
    "# Print the selected column names\n",
    "print(\"Selected features (RF):\", selected_columns)\n",
    "\n",
    "# Print the best score\n",
    "print(\"Best score (RF):\", sfs.k_score_)\n",
    "\n",
    "# Transform X to contain only the selected features\n",
    "X_selected_rf = sfs.transform(X)\n",
    "\n",
    "# Train RF and NN models with selected features\n",
    "rf.fit(X_selected_rf, y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "35d9e116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 18:14:59.645952: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 18:14:59.646143: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 18:14:59.650299: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 18:14:59.671138: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 18:14:59.694629: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 18:14:59.720094: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 18:14:59.742924: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 18:14:59.806574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 18:15:08.090930: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 18:15:08.091197: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 18:15:08.091803: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 18:15:08.093108: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 18:15:08.093169: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 18:15:08.093597: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 18:15:08.096394: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 18:15:08.097422: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_3_input'), name='dense_3_input', description=\"created by layer 'dense_3_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_6_input'), name='dense_6_input', description=\"created by layer 'dense_6_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_6_input'), name='dense_6_input', description=\"created by layer 'dense_6_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_6_input'), name='dense_6_input', description=\"created by layer 'dense_6_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_6_input'), name='dense_6_input', description=\"created by layer 'dense_6_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_6_input'), name='dense_6_input', description=\"created by layer 'dense_6_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_6_input'), name='dense_6_input', description=\"created by layer 'dense_6_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_6_input'), name='dense_6_input', description=\"created by layer 'dense_6_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_6_input'), name='dense_6_input', description=\"created by layer 'dense_6_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_9_input'), name='dense_9_input', description=\"created by layer 'dense_9_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_9_input'), name='dense_9_input', description=\"created by layer 'dense_9_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_9_input'), name='dense_9_input', description=\"created by layer 'dense_9_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_9_input'), name='dense_9_input', description=\"created by layer 'dense_9_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_9_input'), name='dense_9_input', description=\"created by layer 'dense_9_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_9_input'), name='dense_9_input', description=\"created by layer 'dense_9_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_9_input'), name='dense_9_input', description=\"created by layer 'dense_9_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_9_input'), name='dense_9_input', description=\"created by layer 'dense_9_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_12_input'), name='dense_12_input', description=\"created by layer 'dense_12_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_12_input'), name='dense_12_input', description=\"created by layer 'dense_12_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_12_input'), name='dense_12_input', description=\"created by layer 'dense_12_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_12_input'), name='dense_12_input', description=\"created by layer 'dense_12_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_12_input'), name='dense_12_input', description=\"created by layer 'dense_12_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_12_input'), name='dense_12_input', description=\"created by layer 'dense_12_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_12_input'), name='dense_12_input', description=\"created by layer 'dense_12_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_12_input'), name='dense_12_input', description=\"created by layer 'dense_12_input'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n    history = self.model.fit(x, y, **fit_args)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/var/folders/jx/rs472zns1ds_9lgk5hq47qz80000gp/T/__autograph_generated_file4it_cx3p.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 9, but received input with shape (None, 1)\n    \n    Call arguments received by layer \"sequential\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n      • training=True\n      • mask=None\n\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n    history = self.model.fit(x, y, **fit_args)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/var/folders/jx/rs472zns1ds_9lgk5hq47qz80000gp/T/__autograph_generated_file4it_cx3p.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_1\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_3\" is incompatible with the layer: expected axis -1 of input shape to have value 9, but received input with shape (None, 1)\n    \n    Call arguments received by layer \"sequential_1\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n      • training=True\n      • mask=None\n\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n    history = self.model.fit(x, y, **fit_args)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/var/folders/jx/rs472zns1ds_9lgk5hq47qz80000gp/T/__autograph_generated_file4it_cx3p.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_2\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_6\" is incompatible with the layer: expected axis -1 of input shape to have value 9, but received input with shape (None, 1)\n    \n    Call arguments received by layer \"sequential_2\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n      • training=True\n      • mask=None\n\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n    history = self.model.fit(x, y, **fit_args)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/var/folders/jx/rs472zns1ds_9lgk5hq47qz80000gp/T/__autograph_generated_file4it_cx3p.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_3\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_9\" is incompatible with the layer: expected axis -1 of input shape to have value 9, but received input with shape (None, 1)\n    \n    Call arguments received by layer \"sequential_3\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n      • training=True\n      • mask=None\n\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n    history = self.model.fit(x, y, **fit_args)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/var/folders/jx/rs472zns1ds_9lgk5hq47qz80000gp/T/__autograph_generated_file4it_cx3p.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_4\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_12\" is incompatible with the layer: expected axis -1 of input shape to have value 9, but received input with shape (None, 1)\n    \n    Call arguments received by layer \"sequential_4\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n      • training=True\n      • mask=None\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/mlxtend/feature_selection/utilities.py\", line 98, in _calc_score\n    scores = cross_val_score(\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 515, in cross_val_score\n    cv_results = cross_validate(\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 285, in cross_validate\n    _warn_or_raise_about_fit_failures(results, error_score)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 367, in _warn_or_raise_about_fit_failures\n    raise ValueError(all_fits_failed_message)\nValueError: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n    history = self.model.fit(x, y, **fit_args)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/var/folders/jx/rs472zns1ds_9lgk5hq47qz80000gp/T/__autograph_generated_file4it_cx3p.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 9, but received input with shape (None, 1)\n    \n    Call arguments received by layer \"sequential\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n      • training=True\n      • mask=None\n\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n    history = self.model.fit(x, y, **fit_args)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/var/folders/jx/rs472zns1ds_9lgk5hq47qz80000gp/T/__autograph_generated_file4it_cx3p.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_1\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_3\" is incompatible with the layer: expected axis -1 of input shape to have value 9, but received input with shape (None, 1)\n    \n    Call arguments received by layer \"sequential_1\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n      • training=True\n      • mask=None\n\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n    history = self.model.fit(x, y, **fit_args)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/var/folders/jx/rs472zns1ds_9lgk5hq47qz80000gp/T/__autograph_generated_file4it_cx3p.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_2\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_6\" is incompatible with the layer: expected axis -1 of input shape to have value 9, but received input with shape (None, 1)\n    \n    Call arguments received by layer \"sequential_2\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n      • training=True\n      • mask=None\n\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n    history = self.model.fit(x, y, **fit_args)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/var/folders/jx/rs472zns1ds_9lgk5hq47qz80000gp/T/__autograph_generated_file4it_cx3p.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_3\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_9\" is incompatible with the layer: expected axis -1 of input shape to have value 9, but received input with shape (None, 1)\n    \n    Call arguments received by layer \"sequential_3\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n      • training=True\n      • mask=None\n\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n    history = self.model.fit(x, y, **fit_args)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/var/folders/jx/rs472zns1ds_9lgk5hq47qz80000gp/T/__autograph_generated_file4it_cx3p.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_4\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_12\" is incompatible with the layer: expected axis -1 of input shape to have value 9, but received input with shape (None, 1)\n    \n    Call arguments received by layer \"sequential_4\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n      • training=True\n      • mask=None\n\n\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[225], line 19\u001b[0m\n\u001b[1;32m      9\u001b[0m nn \u001b[38;5;241m=\u001b[39m KerasClassifier(build_fn\u001b[38;5;241m=\u001b[39mcreate_nn_model, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     11\u001b[0m sfs_nn \u001b[38;5;241m=\u001b[39m SFS(nn,\n\u001b[1;32m     12\u001b[0m              k_features\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]),\n\u001b[1;32m     13\u001b[0m              forward\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m              cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     17\u001b[0m              n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m sfs_nn \u001b[38;5;241m=\u001b[39m \u001b[43msfs_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Get the selected column names\u001b[39;00m\n\u001b[1;32m     22\u001b[0m selected_columns \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;28mlist\u001b[39m(sfs_nn\u001b[38;5;241m.\u001b[39mk_feature_idx_)]\n",
      "File \u001b[0;32m~/Applications/anaconda3/lib/python3.9/site-packages/mlxtend/feature_selection/sequential_feature_selector.py:545\u001b[0m, in \u001b[0;36mSequentialFeatureSelector.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    542\u001b[0m     search_set \u001b[38;5;241m=\u001b[39m prev_subset\n\u001b[1;32m    543\u001b[0m     must_include_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_features_group_set\n\u001b[0;32m--> 545\u001b[0m k_idx, k_score, cv_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_selector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmust_include_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_forward\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_groups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_groups_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    556\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(k_idx)\n\u001b[1;32m    557\u001b[0m \u001b[38;5;66;03m# floating can lead to multiple same-sized subsets\u001b[39;00m\n",
      "File \u001b[0;32m~/Applications/anaconda3/lib/python3.9/site-packages/mlxtend/feature_selection/sequential_feature_selector.py:777\u001b[0m, in \u001b[0;36mSequentialFeatureSelector._feature_selector\u001b[0;34m(self, search_set, must_include_set, X, y, is_forward, groups, feature_groups, **fit_params)\u001b[0m\n\u001b[1;32m    773\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, n)\n\u001b[1;32m    774\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    775\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_dispatch\n\u001b[1;32m    776\u001b[0m )\n\u001b[0;32m--> 777\u001b[0m work \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_calc_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmust_include_set\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_groups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeature_explorer\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    790\u001b[0m all_avg_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    791\u001b[0m all_cv_scores \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Applications/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1058\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1058\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/Applications/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:933\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 933\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/Applications/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/Applications/anaconda3/lib/python3.9/concurrent/futures/_base.py:445\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/Applications/anaconda3/lib/python3.9/concurrent/futures/_base.py:390\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n    history = self.model.fit(x, y, **fit_args)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/var/folders/jx/rs472zns1ds_9lgk5hq47qz80000gp/T/__autograph_generated_file4it_cx3p.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 9, but received input with shape (None, 1)\n    \n    Call arguments received by layer \"sequential\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n      • training=True\n      • mask=None\n\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n    history = self.model.fit(x, y, **fit_args)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/var/folders/jx/rs472zns1ds_9lgk5hq47qz80000gp/T/__autograph_generated_file4it_cx3p.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_1\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_3\" is incompatible with the layer: expected axis -1 of input shape to have value 9, but received input with shape (None, 1)\n    \n    Call arguments received by layer \"sequential_1\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n      • training=True\n      • mask=None\n\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n    history = self.model.fit(x, y, **fit_args)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/var/folders/jx/rs472zns1ds_9lgk5hq47qz80000gp/T/__autograph_generated_file4it_cx3p.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_2\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_6\" is incompatible with the layer: expected axis -1 of input shape to have value 9, but received input with shape (None, 1)\n    \n    Call arguments received by layer \"sequential_2\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n      • training=True\n      • mask=None\n\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n    history = self.model.fit(x, y, **fit_args)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/var/folders/jx/rs472zns1ds_9lgk5hq47qz80000gp/T/__autograph_generated_file4it_cx3p.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_3\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_9\" is incompatible with the layer: expected axis -1 of input shape to have value 9, but received input with shape (None, 1)\n    \n    Call arguments received by layer \"sequential_3\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n      • training=True\n      • mask=None\n\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n    history = self.model.fit(x, y, **fit_args)\n  File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/var/folders/jx/rs472zns1ds_9lgk5hq47qz80000gp/T/__autograph_generated_file4it_cx3p.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/Sravan/Applications/anaconda3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_4\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"dense_12\" is incompatible with the layer: expected axis -1 of input shape to have value 9, but received input with shape (None, 1)\n    \n    Call arguments received by layer \"sequential_4\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=float32)\n      • training=True\n      • mask=None\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_nn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "nn = KerasClassifier(build_fn=create_nn_model, epochs=100, batch_size=10, verbose=0)\n",
    "\n",
    "sfs_nn = SFS(nn,\n",
    "             k_features=(1, X.shape[1]),\n",
    "             forward=True,\n",
    "             floating=True,\n",
    "             scoring='accuracy',\n",
    "             cv=5,\n",
    "             n_jobs=-1)\n",
    "\n",
    "sfs_nn = sfs_nn.fit(np.array(X), np.array(y))\n",
    "\n",
    "# Get the selected column names\n",
    "selected_columns = X.columns[list(sfs_nn.k_feature_idx_)]\n",
    "\n",
    "# Print the selected column names\n",
    "print(\"Selected features (NN):\", selected_columns)\n",
    "\n",
    "# Print the best score\n",
    "print(\"Best score (NN):\", sfs_nn.k_score_)\n",
    "\n",
    "# Transform X to contain only the selected features\n",
    "X_selected_rf = sfs_nn.transform(X)\n",
    "\n",
    "# Train RF and NN models with selected features\n",
    "nn.fit(X_selected_rf, y)\n",
    "\n",
    "print(\"Selected features (NN):\", sfs_nn.k_feature_idx_)\n",
    "print(\"Best score (NN):\", sfs_nn.k_score_)\n",
    "\n",
    "X_selected_nn = sfs_nn.transform(X)\n",
    "nn.fit(np.array(X_selected_nn), np.array(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3033e974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
